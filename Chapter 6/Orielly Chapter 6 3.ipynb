{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3b94d92-d790-484e-8938-d08fe32fbf6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLflow Experiment Tracking and Model Registry with Unity Catalog\n",
    "\n",
    "## Scenario\n",
    "You are a data scientist at a financial services company building predictive models for customer churn. While your team has successfully trained several models, leadership is concerned about governance, auditability, and compliance. Regulators require a full record of how models are developed, deployed, and retired.\n",
    "\n",
    "## Objectives\n",
    "By the end of this lab, you will be able to:\n",
    "- Track experiments with MLflow by logging parameters, metrics, and artifacts\n",
    "- Register models in the MLflow Model Registry integrated with Unity Catalog\n",
    "- Manage versions and promote models between Staging, Production, and Archived\n",
    "- Apply Unity Catalog governance controls (RBAC, audit logging, and lineage)\n",
    "- Implement reproducibility practices through metadata and documentation\n",
    "- Apply archiving and cleanup policies to maintain a healthy model registry\n",
    "\n",
    "## Prerequisites\n",
    "- Databricks workspace with Unity Catalog enabled\n",
    "- Access to create catalogs, schemas, and tables\n",
    "- MLflow installed (pre-installed in Databricks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4baf3b1-dd2e-462e-9034-d14ce1053153",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 1: Environment Setup and Prerequisites\n",
    "\n",
    "In this section, we will:\n",
    "1. Import necessary libraries\n",
    "2. Configure Unity Catalog settings\n",
    "3. Create sample customer churn data\n",
    "\n",
    "**Why this matters:** Proper environment setup ensures reproducibility and governance from the start. Unity Catalog provides enterprise-grade data governance, while MLflow handles model lifecycle management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "711c50c0-389c-4dc9-9bec-d25538680c08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully\nMLflow version: 3.0.1\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cc86168-67f8-4537-9c4b-75d00d930b75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Configure Unity Catalog Settings\n",
    "\n",
    "We'll set up our Unity Catalog namespace structure:\n",
    "- **Catalog**: `financial_services` - Top-level container for our data\n",
    "- **Schema**: `churn_models` - Logical grouping for churn-related assets\n",
    "- **Volume**: For storing model artifacts and documentation\n",
    "\n",
    "**Governance Note:** Unity Catalog provides centralized access control, audit logging, and data lineage across all assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "434d7f04-ba09-4a95-a43d-79c357fef4b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Unity Catalog configured:\n  - Catalog: financial_services\n  - Schema: churn_models\n  - Model Registry: financial_services.churn_models.customer_churn_model\n"
     ]
    }
   ],
   "source": [
    "# Define Unity Catalog namespace\n",
    "CATALOG_NAME = \"financial_services\"\n",
    "SCHEMA_NAME = \"churn_models\"\n",
    "TABLE_NAME = \"customer_churn_data\"\n",
    "MODEL_NAME = f\"{CATALOG_NAME}.{SCHEMA_NAME}.customer_churn_model\"\n",
    "\n",
    "# Create catalog and schema if they don't exist\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG_NAME}\")\n",
    "spark.sql(f\"USE CATALOG {CATALOG_NAME}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA_NAME}\")\n",
    "spark.sql(f\"USE SCHEMA {SCHEMA_NAME}\")\n",
    "\n",
    "print(f\"✓ Unity Catalog configured:\")\n",
    "print(f\"  - Catalog: {CATALOG_NAME}\")\n",
    "print(f\"  - Schema: {SCHEMA_NAME}\")\n",
    "print(f\"  - Model Registry: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ef09385-3946-45b1-9e42-3f4188cd6b3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Generate Sample Customer Churn Data\n",
    "\n",
    "We'll create a realistic customer dataset with features commonly used in churn prediction:\n",
    "- **Customer Demographics**: Age, tenure, account type\n",
    "- **Usage Patterns**: Transaction frequency, product usage, support interactions\n",
    "- **Financial Metrics**: Account balance, credit score, monthly charges\n",
    "- **Target Variable**: Churn (1 = churned, 0 = retained)\n",
    "\n",
    "**Data Governance:** This data will be stored in Unity Catalog with full lineage tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc977d3d-9c97-42be-8ddb-16d28001e1bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated 10,000 customer records\n✓ Churn rate: 20.49%\n\nFeature summary:\n                age  tenure_months  ...  last_transaction_days         churn\ncount  10000.000000   10000.000000  ...           10000.000000  10000.000000\nmean      46.166100      60.051300  ...              44.571300      0.204900\nstd       16.421738      34.146676  ...              26.128057      0.403649\nmin       18.000000       1.000000  ...               0.000000      0.000000\n25%       32.000000      30.000000  ...              22.000000      0.000000\n50%       46.000000      60.000000  ...              45.000000      0.000000\n75%       61.000000      89.000000  ...              67.000000      0.000000\nmax       74.000000     119.000000  ...              89.000000      1.000000\n\n[8 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample data\n",
    "n_customers = 10000\n",
    "\n",
    "# Create customer IDs\n",
    "customer_ids = [f\"CUST_{str(i).zfill(6)}\" for i in range(1, n_customers + 1)]\n",
    "\n",
    "# Generate features\n",
    "data = {\n",
    "    'customer_id': customer_ids,\n",
    "    'age': np.random.randint(18, 75, n_customers),\n",
    "    'tenure_months': np.random.randint(1, 120, n_customers),\n",
    "    'account_balance': np.random.uniform(100, 50000, n_customers).round(2),\n",
    "    'credit_score': np.random.randint(300, 850, n_customers),\n",
    "    'num_products': np.random.randint(1, 5, n_customers),\n",
    "    'monthly_charges': np.random.uniform(20, 500, n_customers).round(2),\n",
    "    'total_transactions': np.random.randint(0, 200, n_customers),\n",
    "    'support_calls': np.random.randint(0, 15, n_customers),\n",
    "    'complaint_filed': np.random.choice([0, 1], n_customers, p=[0.85, 0.15]),\n",
    "    'account_type': np.random.choice(['Basic', 'Premium', 'Gold'], n_customers, p=[0.5, 0.35, 0.15]),\n",
    "    'online_banking': np.random.choice([0, 1], n_customers, p=[0.3, 0.7]),\n",
    "    'mobile_app_usage': np.random.randint(0, 100, n_customers),\n",
    "    'last_transaction_days': np.random.randint(0, 90, n_customers)\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_pandas = pd.DataFrame(data)\n",
    "\n",
    "# Generate churn target with realistic correlations\n",
    "churn_probability = (\n",
    "    0.1 +  # Base churn rate\n",
    "    (df_pandas['support_calls'] > 5) * 0.2 +\n",
    "    (df_pandas['complaint_filed'] == 1) * 0.25 +\n",
    "    (df_pandas['tenure_months'] < 12) * 0.15 +\n",
    "    (df_pandas['last_transaction_days'] > 60) * 0.2 +\n",
    "    (df_pandas['account_balance'] < 1000) * 0.1 -\n",
    "    (df_pandas['num_products'] > 2) * 0.15 -\n",
    "    (df_pandas['online_banking'] == 1) * 0.1\n",
    ")\n",
    "\n",
    "# Clip probabilities and generate churn\n",
    "churn_probability = np.clip(churn_probability, 0, 0.8)\n",
    "df_pandas['churn'] = np.random.binomial(1, churn_probability)\n",
    "\n",
    "# Add timestamp for audit purposes\n",
    "df_pandas['data_created_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(f\"✓ Generated {n_customers:,} customer records\")\n",
    "print(f\"✓ Churn rate: {df_pandas['churn'].mean():.2%}\")\n",
    "print(f\"\\nFeature summary:\")\n",
    "print(df_pandas.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0ba9e7c-9d90-4e3c-b7df-4fa9a38eed0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Save Data to Unity Catalog\n",
    "\n",
    "We'll persist our customer data to Unity Catalog as a Delta table. This provides:\n",
    "- **ACID transactions** for data reliability\n",
    "- **Time travel** for auditing and compliance\n",
    "- **Automatic lineage tracking** through Unity Catalog\n",
    "- **Fine-grained access control** via RBAC\n",
    "\n",
    "**Compliance Note:** All data access and modifications are automatically logged by Unity Catalog for regulatory audits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9d16ff7-694d-457d-bc0d-83161f50e30c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data saved to Unity Catalog table: financial_services.churn_models.customer_churn_data\n✓ Table contains 10,000 records\n\nSample records:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>customer_id</th><th>age</th><th>tenure_months</th><th>account_balance</th><th>credit_score</th><th>num_products</th><th>monthly_charges</th><th>total_transactions</th><th>support_calls</th><th>complaint_filed</th><th>account_type</th><th>online_banking</th><th>mobile_app_usage</th><th>last_transaction_days</th><th>churn</th><th>data_created_at</th></tr></thead><tbody><tr><td>CUST_000001</td><td>56</td><td>102</td><td>9754.44</td><td>849</td><td>4</td><td>477.56</td><td>45</td><td>12</td><td>0</td><td>Gold</td><td>1</td><td>29</td><td>71</td><td>0</td><td>2025-10-06 00:07:23</td></tr><tr><td>CUST_000002</td><td>69</td><td>28</td><td>44612.3</td><td>423</td><td>1</td><td>352.88</td><td>179</td><td>2</td><td>0</td><td>Basic</td><td>1</td><td>17</td><td>26</td><td>0</td><td>2025-10-06 00:07:23</td></tr><tr><td>CUST_000003</td><td>46</td><td>48</td><td>1649.98</td><td>659</td><td>4</td><td>301.01</td><td>15</td><td>10</td><td>0</td><td>Gold</td><td>0</td><td>38</td><td>3</td><td>0</td><td>2025-10-06 00:07:23</td></tr><tr><td>CUST_000004</td><td>32</td><td>38</td><td>44780.27</td><td>363</td><td>2</td><td>174.79</td><td>107</td><td>6</td><td>0</td><td>Premium</td><td>1</td><td>77</td><td>75</td><td>0</td><td>2025-10-06 00:07:23</td></tr><tr><td>CUST_000005</td><td>60</td><td>31</td><td>2620.96</td><td>401</td><td>1</td><td>227.86</td><td>138</td><td>8</td><td>0</td><td>Premium</td><td>0</td><td>62</td><td>84</td><td>1</td><td>2025-10-06 00:07:23</td></tr><tr><td>CUST_000006</td><td>25</td><td>14</td><td>33325.88</td><td>576</td><td>2</td><td>62.91</td><td>17</td><td>7</td><td>0</td><td>Basic</td><td>1</td><td>14</td><td>19</td><td>1</td><td>2025-10-06 00:07:23</td></tr><tr><td>CUST_000007</td><td>38</td><td>117</td><td>3676.8</td><td>526</td><td>4</td><td>499.11</td><td>107</td><td>10</td><td>0</td><td>Basic</td><td>0</td><td>49</td><td>47</td><td>1</td><td>2025-10-06 00:07:23</td></tr><tr><td>CUST_000008</td><td>56</td><td>97</td><td>35340.03</td><td>322</td><td>2</td><td>382.44</td><td>183</td><td>12</td><td>0</td><td>Basic</td><td>0</td><td>52</td><td>52</td><td>0</td><td>2025-10-06 00:07:23</td></tr><tr><td>CUST_000009</td><td>36</td><td>73</td><td>1795.17</td><td>363</td><td>2</td><td>318.3</td><td>183</td><td>1</td><td>0</td><td>Basic</td><td>1</td><td>99</td><td>62</td><td>0</td><td>2025-10-06 00:07:23</td></tr><tr><td>CUST_000010</td><td>40</td><td>91</td><td>42138.64</td><td>456</td><td>2</td><td>302.13</td><td>184</td><td>14</td><td>0</td><td>Basic</td><td>1</td><td>86</td><td>16</td><td>0</td><td>2025-10-06 00:07:23</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "CUST_000001",
         56,
         102,
         9754.44,
         849,
         4,
         477.56,
         45,
         12,
         0,
         "Gold",
         1,
         29,
         71,
         0,
         "2025-10-06 00:07:23"
        ],
        [
         "CUST_000002",
         69,
         28,
         44612.3,
         423,
         1,
         352.88,
         179,
         2,
         0,
         "Basic",
         1,
         17,
         26,
         0,
         "2025-10-06 00:07:23"
        ],
        [
         "CUST_000003",
         46,
         48,
         1649.98,
         659,
         4,
         301.01,
         15,
         10,
         0,
         "Gold",
         0,
         38,
         3,
         0,
         "2025-10-06 00:07:23"
        ],
        [
         "CUST_000004",
         32,
         38,
         44780.27,
         363,
         2,
         174.79,
         107,
         6,
         0,
         "Premium",
         1,
         77,
         75,
         0,
         "2025-10-06 00:07:23"
        ],
        [
         "CUST_000005",
         60,
         31,
         2620.96,
         401,
         1,
         227.86,
         138,
         8,
         0,
         "Premium",
         0,
         62,
         84,
         1,
         "2025-10-06 00:07:23"
        ],
        [
         "CUST_000006",
         25,
         14,
         33325.88,
         576,
         2,
         62.91,
         17,
         7,
         0,
         "Basic",
         1,
         14,
         19,
         1,
         "2025-10-06 00:07:23"
        ],
        [
         "CUST_000007",
         38,
         117,
         3676.8,
         526,
         4,
         499.11,
         107,
         10,
         0,
         "Basic",
         0,
         49,
         47,
         1,
         "2025-10-06 00:07:23"
        ],
        [
         "CUST_000008",
         56,
         97,
         35340.03,
         322,
         2,
         382.44,
         183,
         12,
         0,
         "Basic",
         0,
         52,
         52,
         0,
         "2025-10-06 00:07:23"
        ],
        [
         "CUST_000009",
         36,
         73,
         1795.17,
         363,
         2,
         318.3,
         183,
         1,
         0,
         "Basic",
         1,
         99,
         62,
         0,
         "2025-10-06 00:07:23"
        ],
        [
         "CUST_000010",
         40,
         91,
         42138.64,
         456,
         2,
         302.13,
         184,
         14,
         0,
         "Basic",
         1,
         86,
         16,
         0,
         "2025-10-06 00:07:23"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "customer_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "tenure_months",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "account_balance",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "credit_score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_products",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "monthly_charges",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_transactions",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "support_calls",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "complaint_filed",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "account_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "online_banking",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "mobile_app_usage",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "last_transaction_days",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "churn",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "data_created_at",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert to Spark DataFrame and save to Unity Catalog\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Write to Delta table in Unity Catalog\n",
    "table_path = f\"{CATALOG_NAME}.{SCHEMA_NAME}.{TABLE_NAME}\"\n",
    "df_spark.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_path)\n",
    "\n",
    "print(f\"✓ Data saved to Unity Catalog table: {table_path}\")\n",
    "\n",
    "# Verify table creation and show sample\n",
    "df_loaded = spark.table(table_path)\n",
    "print(f\"✓ Table contains {df_loaded.count():,} records\")\n",
    "print(\"\\nSample records:\")\n",
    "display(df_loaded.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4bf4dc0-b697-4c5c-8da6-61a0d8c06d2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Quality Checks\n",
    "\n",
    "Before model training, we perform data quality validation:\n",
    "- Check for missing values\n",
    "- Verify data distributions\n",
    "- Validate business rules\n",
    "\n",
    "**Best Practice:** Document data quality checks for reproducibility and compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7384027c-1a73-440b-97f5-fded803b61f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Quality Report ===\n\nMissing Values:\n✓ No missing values\n\nClass Distribution:\n  - Retained (0): 7,951 (79.51%)\n  - Churned (1): 2,049 (20.49%)\n\nTop Features Correlated with Churn:\ncomplaint_filed          0.200859\nsupport_calls            0.183364\nlast_transaction_days    0.177956\nnum_products             0.136782\nonline_banking           0.094292\ntenure_months            0.054275\nmonthly_charges          0.010869\ntotal_transactions       0.009298\naccount_balance          0.006241\ncredit_score             0.003969\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Perform data quality checks\n",
    "print(\"=== Data Quality Report ===\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_counts = df_pandas.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_counts[missing_counts > 0] if missing_counts.sum() > 0 else \"✓ No missing values\")\n",
    "\n",
    "# Check class balance\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(f\"  - Retained (0): {(df_pandas['churn'] == 0).sum():,} ({(df_pandas['churn'] == 0).mean():.2%})\")\n",
    "print(f\"  - Churned (1): {(df_pandas['churn'] == 1).sum():,} ({(df_pandas['churn'] == 1).mean():.2%})\")\n",
    "\n",
    "# Feature correlations with target\n",
    "print(f\"\\nTop Features Correlated with Churn:\")\n",
    "numeric_cols = df_pandas.select_dtypes(include=[np.number]).columns.drop('churn')\n",
    "correlations = df_pandas[numeric_cols].corrwith(df_pandas['churn']).abs().sort_values(ascending=False)\n",
    "print(correlations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96e05b07-e2f9-496e-a5c9-8f174a55bfb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 2: Data Preparation and Feature Engineering\n",
    "\n",
    "In this section, we'll:\n",
    "1. Prepare features for modeling\n",
    "2. Split data into train/test sets\n",
    "3. Apply feature scaling\n",
    "\n",
    "**MLflow Integration:** All preprocessing steps will be logged as artifacts for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "130edeee-7517-447d-aad4-59fb94392a8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature matrix shape: (10000, 14)\n✓ Target variable shape: (10000,)\n\nFeatures used for modeling:\n  1. age\n  2. tenure_months\n  3. account_balance\n  4. credit_score\n  5. num_products\n  6. monthly_charges\n  7. total_transactions\n  8. support_calls\n  9. complaint_filed\n  10. online_banking\n  11. mobile_app_usage\n  12. last_transaction_days\n  13. account_type_Gold\n  14. account_type_Premium\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for modeling\n",
    "# One-hot encode categorical variables\n",
    "df_encoded = pd.get_dummies(df_pandas, columns=['account_type'], drop_first=True)\n",
    "\n",
    "# Select feature columns (exclude ID, timestamp, and target)\n",
    "feature_cols = [col for col in df_encoded.columns\n",
    "                if col not in ['customer_id', 'churn', 'data_created_at']]\n",
    "\n",
    "X = df_encoded[feature_cols]\n",
    "y = df_encoded['churn']\n",
    "\n",
    "print(f\"✓ Feature matrix shape: {X.shape}\")\n",
    "print(f\"✓ Target variable shape: {y.shape}\")\n",
    "print(f\"\\nFeatures used for modeling:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42343a48-931e-418d-b850-fb99a5c467b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training set: 8,000 samples\n✓ Test set: 2,000 samples\n\nTrain set churn rate: 20.49%\nTest set churn rate: 20.50%\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"✓ Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"✓ Test set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"\\nTrain set churn rate: {y_train.mean():.2%}\")\n",
    "print(f\"Test set churn rate: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c37ed25c-9802-40ee-8177-ca050de60e18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature scaling completed\n✓ Scaled training data shape: (8000, 14)\n✓ Scaled test data shape: (2000, 14)\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"✓ Feature scaling completed\")\n",
    "print(f\"✓ Scaled training data shape: {X_train_scaled.shape}\")\n",
    "print(f\"✓ Scaled test data shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2caaa6b4-5afe-4eca-b317-d3b8c4069bd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 3: MLflow Experiment Tracking\n",
    "\n",
    "Now we'll train multiple models and track everything with MLflow:\n",
    "- **Parameters**: Model hyperparameters\n",
    "- **Metrics**: Accuracy, precision, recall, F1, AUC\n",
    "- **Artifacts**: Model files, feature importance plots, confusion matrices\n",
    "- **Tags**: Metadata for organization and searchability\n",
    "\n",
    "**Enterprise Value:** Complete experiment tracking enables reproducibility, comparison, and audit trails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf4c46f7-5593-475a-8a10-65b0a35ed2fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MLflow experiment: /Users/rajaniesh@rajanieshkaushikk.com/churn_prediction_experiments\n✓ Model registry: Unity Catalog\n✓ Registry URI: databricks-uc\n"
     ]
    }
   ],
   "source": [
    "# Set up MLflow experiment\n",
    "experiment_name = f\"/Users/{spark.sql('SELECT current_user()').collect()[0][0]}/churn_prediction_experiments\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Configure MLflow to use Unity Catalog for model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "print(f\"✓ MLflow experiment: {experiment_name}\")\n",
    "print(f\"✓ Model registry: Unity Catalog\")\n",
    "print(f\"✓ Registry URI: {mlflow.get_registry_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66b3460c-4046-406f-8229-aa61e64bae6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Helper Function: Model Training and Logging\n",
    "\n",
    "We'll create a reusable function that:\n",
    "- Trains a model\n",
    "- Logs all parameters, metrics, and artifacts to MLflow\n",
    "- Returns performance metrics for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9f73231-cea2-43c8-8f8b-af536db280ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper function defined\n"
     ]
    }
   ],
   "source": [
    "def train_and_log_model(model, model_name, X_train, X_test, y_train, y_test, params=None):\n",
    "    \"\"\"\n",
    "    Train a model and log everything to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: Sklearn model instance\n",
    "        model_name: Name for the MLflow run\n",
    "        X_train, X_test, y_train, y_test: Train/test data\n",
    "        params: Dictionary of hyperparameters to log\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of metrics\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=model_name) as run:\n",
    "        # Log parameters\n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "        # Log model type and training metadata\n",
    "        mlflow.set_tag(\"model_type\", model.__class__.__name__)\n",
    "        mlflow.set_tag(\"training_date\", datetime.now().strftime('%Y-%m-%d'))\n",
    "        mlflow.set_tag(\"data_version\", \"v1.0\")\n",
    "        mlflow.set_tag(\"purpose\", \"customer_churn_prediction\")\n",
    "\n",
    "        # Train model\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        y_pred_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'train_accuracy': accuracy_score(y_train, y_pred_train),\n",
    "            'test_accuracy': accuracy_score(y_test, y_pred_test),\n",
    "            'test_precision': precision_score(y_test, y_pred_test),\n",
    "            'test_recall': recall_score(y_test, y_pred_test),\n",
    "            'test_f1': f1_score(y_test, y_pred_test),\n",
    "            'test_auc': roc_auc_score(y_test, y_pred_proba_test)\n",
    "        }\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Log model with signature\n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            \"model\",\n",
    "            signature=signature,\n",
    "            input_example=X_train[:5]\n",
    "        )\n",
    "\n",
    "        # Log feature importance if available\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': X.columns,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.barh(feature_importance['feature'][:10], feature_importance['importance'][:10])\n",
    "            plt.xlabel('Importance')\n",
    "            plt.title(f'Top 10 Feature Importances - {model_name}')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('/tmp/feature_importance.png')\n",
    "            mlflow.log_artifact('/tmp/feature_importance.png')\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"✓ {model_name} training complete\")\n",
    "        print(f\"  Run ID: {run.info.run_id}\")\n",
    "        print(f\"  Metrics: {metrics}\")\n",
    "\n",
    "        return metrics, run.info.run_id\n",
    "\n",
    "print(\"✓ Helper function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6db4a48c-b2d4-4c41-8015-8d223795f1e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train Multiple Models\n",
    "\n",
    "We'll train three different models to compare performance:\n",
    "1. **Logistic Regression** - Simple, interpretable baseline\n",
    "2. **Random Forest** - Ensemble method with feature importance\n",
    "3. **Gradient Boosting** - Advanced ensemble technique\n",
    "\n",
    "Each model's parameters, metrics, and artifacts will be logged to MLflow for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca85f87-ac12-49f3-9123-b729cbaeed28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 00:07:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTraining Logistic_Regression_Baseline...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 View Logged Model at: https://adb-3141834805281315.15.azuredatabricks.net/ml/experiments/3522400443005898/models/m-e830de514967461f8d2a46a68b6330af?o=3141834805281315\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Logistic_Regression_Baseline training complete\n  Run ID: 7e4453880c084e32ba098ba9f94c0f45\n  Metrics: {'train_accuracy': 0.80325, 'test_accuracy': 0.805, 'test_precision': 0.5847457627118644, 'test_recall': 0.16829268292682928, 'test_f1': 0.26136363636363635, 'test_auc': np.float64(0.7550544562049393)}\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "lr_params = {\n",
    "    'max_iter': 1000,\n",
    "    'random_state': 42,\n",
    "    'solver': 'lbfgs'\n",
    "}\n",
    "\n",
    "lr_model = LogisticRegression(**lr_params)\n",
    "lr_metrics, lr_run_id = train_and_log_model(\n",
    "    lr_model,\n",
    "    \"Logistic_Regression_Baseline\",\n",
    "    X_train_scaled,\n",
    "    X_test_scaled,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    lr_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d39df29-3265-40f8-bf68-25470652a8a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTraining Random_Forest_v1...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 00:07:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n\uD83D\uDD17 View Logged Model at: https://adb-3141834805281315.15.azuredatabricks.net/ml/experiments/3522400443005898/models/m-53f6c47bb185439099453d582179cbf2?o=3141834805281315\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random_Forest_v1 training complete\n  Run ID: 5a6f916965be46f2899886a76c9843ad\n  Metrics: {'train_accuracy': 0.868625, 'test_accuracy': 0.8065, 'test_precision': 0.6666666666666666, 'test_recall': 0.11219512195121951, 'test_f1': 0.19206680584551147, 'test_auc': np.float64(0.7753044945543794)}\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_metrics, rf_run_id = train_and_log_model(\n",
    "    rf_model,\n",
    "    \"Random_Forest_v1\",\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    rf_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fd0b138-e3d0-4f52-880a-50def6bf7760",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTraining Gradient_Boosting_v1...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 00:08:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n\uD83D\uDD17 View Logged Model at: https://adb-3141834805281315.15.azuredatabricks.net/ml/experiments/3522400443005898/models/m-d2e466e4281f46ba9128408643e9f370?o=3141834805281315\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gradient_Boosting_v1 training complete\n  Run ID: 6ee2b020387b4659b4271c72a1b1bc50\n  Metrics: {'train_accuracy': 0.882625, 'test_accuracy': 0.803, 'test_precision': 0.5470588235294118, 'test_recall': 0.22682926829268293, 'test_f1': 0.32068965517241377, 'test_auc': np.float64(0.7703267372296365)}\n"
     ]
    }
   ],
   "source": [
    "# Train Gradient Boosting\n",
    "gb_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "gb_model = GradientBoostingClassifier(**gb_params)\n",
    "gb_metrics, gb_run_id = train_and_log_model(\n",
    "    gb_model,\n",
    "    \"Gradient_Boosting_v1\",\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    gb_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "578ef63b-7226-4fc5-b170-53f436fdbc0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Compare Model Performance\n",
    "\n",
    "Let's compare all three models across key metrics to determine which performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3735b248-982a-45fd-b9d7-ace8460b2eb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Performance Comparison ===\n\n              Model                           Run_ID  Accuracy  Precision   Recall  F1_Score      AUC\nLogistic Regression 7e4453880c084e32ba098ba9f94c0f45    0.8050   0.584746 0.168293  0.261364 0.755054\n      Random Forest 5a6f916965be46f2899886a76c9843ad    0.8065   0.666667 0.112195  0.192067 0.775304\n  Gradient Boosting 6ee2b020387b4659b4271c72a1b1bc50    0.8030   0.547059 0.226829  0.320690 0.770327\n\n✓ Best performing model: Gradient Boosting\n✓ Run ID: 6ee2b020387b4659b4271c72a1b1bc50\n"
     ]
    }
   ],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Gradient Boosting'],\n",
    "    'Run_ID': [lr_run_id, rf_run_id, gb_run_id],\n",
    "    'Accuracy': [lr_metrics['test_accuracy'], rf_metrics['test_accuracy'], gb_metrics['test_accuracy']],\n",
    "    'Precision': [lr_metrics['test_precision'], rf_metrics['test_precision'], gb_metrics['test_precision']],\n",
    "    'Recall': [lr_metrics['test_recall'], rf_metrics['test_recall'], gb_metrics['test_recall']],\n",
    "    'F1_Score': [lr_metrics['test_f1'], rf_metrics['test_f1'], gb_metrics['test_f1']],\n",
    "    'AUC': [lr_metrics['test_auc'], rf_metrics['test_auc'], gb_metrics['test_auc']]\n",
    "})\n",
    "\n",
    "print(\"=== Model Performance Comparison ===\\n\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Identify best model based on F1 score (balanced metric)\n",
    "best_model_idx = comparison_df['F1_Score'].idxmax()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Model']\n",
    "best_run_id = comparison_df.loc[best_model_idx, 'Run_ID']\n",
    "\n",
    "print(f\"\\n✓ Best performing model: {best_model_name}\")\n",
    "print(f\"✓ Run ID: {best_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97da5deb-4097-4217-ab4b-b9f8815b8156",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 4: Model Registration in Unity Catalog\n",
    "\n",
    "Now we'll register our best model in Unity Catalog's Model Registry. This provides:\n",
    "- **Centralized model storage** with versioning\n",
    "- **Access control** via Unity Catalog RBAC\n",
    "- **Audit logging** of all model operations\n",
    "- **Lineage tracking** from data to model to deployment\n",
    "\n",
    "**Governance Benefit:** Unity Catalog ensures only authorized users can access, modify, or deploy models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32c771f2-a5de-49c8-b7e4-ed8301b3f5c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering Gradient Boosting to Unity Catalog...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'financial_services.churn_models.customer_churn_model' already exists. Creating a new version of this model...\n2025/10/06 00:08:13 WARNING mlflow.tracking._model_registry.fluent: Run with id 6ee2b020387b4659b4271c72a1b1bc50 has no artifacts at artifact path 'model', registering model based on models:/m-d2e466e4281f46ba9128408643e9f370 instead\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cfe73ad20a4f5b840ec72b6b4e5939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2608724aaf104edfa837db1c2878f1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 Created version '39' of model 'financial_services.churn_models.customer_churn_model': https://adb-3141834805281315.15.azuredatabricks.net/explore/data/models/financial_services/churn_models/customer_churn_model/version/39?o=3141834805281315\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model registered successfully!\n  Model Name: financial_services.churn_models.customer_churn_model\n  Version: 39\n  Run ID: 6ee2b020387b4659b4271c72a1b1bc50\n"
     ]
    }
   ],
   "source": [
    "# Register the best model to Unity Catalog\n",
    "print(f\"Registering {best_model_name} to Unity Catalog...\")\n",
    "\n",
    "# Create model registry entry\n",
    "model_version = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{best_run_id}/model\",\n",
    "    name=MODEL_NAME,\n",
    "    tags={\n",
    "        \"model_type\": best_model_name,\n",
    "        \"training_date\": datetime.now().strftime('%Y-%m-%d'),\n",
    "        \"use_case\": \"customer_churn_prediction\",\n",
    "        \"department\": \"data_science\",\n",
    "        \"compliance_approved\": \"pending\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✓ Model registered successfully!\")\n",
    "print(f\"  Model Name: {MODEL_NAME}\")\n",
    "print(f\"  Version: {model_version.version}\")\n",
    "print(f\"  Run ID: {best_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f16c7849-1934-489e-b8de-7bdc392b6bb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Add Model Description and Documentation\n",
    "\n",
    "Proper documentation is critical for governance and compliance. We'll add:\n",
    "- Model description\n",
    "- Training details\n",
    "- Performance metrics\n",
    "- Intended use and limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd234ad0-1b70-4270-a859-d0a64850f3c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model documentation added\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Update model description\n",
    "model_description = f\"\"\"\n",
    "# Customer Churn Prediction Model\n",
    "\n",
    "## Overview\n",
    "This model predicts customer churn for financial services customers using {best_model_name}.\n",
    "\n",
    "## Training Details\n",
    "- **Training Date**: {datetime.now().strftime('%Y-%m-%d')}\n",
    "- **Training Data**: {X_train.shape[0]:,} samples\n",
    "- **Features**: {X_train.shape[1]} features\n",
    "- **Algorithm**: {best_model_name}\n",
    "\n",
    "## Performance Metrics (Test Set)\n",
    "- **Accuracy**: {comparison_df.loc[best_model_idx, 'Accuracy']:.4f}\n",
    "- **Precision**: {comparison_df.loc[best_model_idx, 'Precision']:.4f}\n",
    "- **Recall**: {comparison_df.loc[best_model_idx, 'Recall']:.4f}\n",
    "- **F1 Score**: {comparison_df.loc[best_model_idx, 'F1_Score']:.4f}\n",
    "- **AUC-ROC**: {comparison_df.loc[best_model_idx, 'AUC']:.4f}\n",
    "\n",
    "## Intended Use\n",
    "- Predict customer churn probability\n",
    "- Identify at-risk customers for retention campaigns\n",
    "- Support business decision-making\n",
    "\n",
    "## Limitations\n",
    "- Model trained on historical data; performance may degrade over time\n",
    "- Requires retraining with fresh data quarterly\n",
    "- Not suitable for real-time predictions without proper infrastructure\n",
    "\n",
    "## Compliance Notes\n",
    "- All training data stored in Unity Catalog with access controls\n",
    "- Model training tracked in MLflow for full reproducibility\n",
    "- Audit logs available through Unity Catalog\n",
    "\"\"\"\n",
    "\n",
    "# Update model version description\n",
    "client.update_model_version(\n",
    "    name=MODEL_NAME,\n",
    "    version=model_version.version,\n",
    "    description=model_description\n",
    ")\n",
    "\n",
    "print(\"✓ Model documentation added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f905034-4adf-4e18-8bd8-514a5e418a49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 5: Model Version Management and Promotion\n",
    "\n",
    "Unity Catalog supports model lifecycle management through aliases. We'll:\n",
    "1. Set the \"Champion\" alias for production deployment\n",
    "2. Set the \"Challenger\" alias for A/B testing\n",
    "3. Demonstrate version management\n",
    "\n",
    "**Best Practice:** Use aliases instead of stages for flexible deployment strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be273e7a-ef51-4b83-8df8-3072b0459d03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model version 39 promoted to 'Champion' (Production)\n  This model is now ready for production deployment\n"
     ]
    }
   ],
   "source": [
    "# Set Champion alias (production model)\n",
    "client.set_registered_model_alias(\n",
    "    name=MODEL_NAME,\n",
    "    alias=\"Champion\",\n",
    "    version=model_version.version\n",
    ")\n",
    "\n",
    "print(f\"✓ Model version {model_version.version} promoted to 'Champion' (Production)\")\n",
    "print(f\"  This model is now ready for production deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51d32548-10b5-43e6-9e15-7dd1d8fc79b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load Model from Registry\n",
    "\n",
    "Demonstrate how to load a registered model for inference. This is how production systems would access the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17a5f29f-6ed9-40a7-929e-f215f1db0065",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfcfcfe0bdc4a2cb9e7965b00a6b5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded from registry using 'Champion' alias\n\nSample Predictions:\n Customer_Index  Predicted_Churn  Actual_Churn\n           4077                0             0\n           7549                0             0\n           4396                0             0\n           2717                0             0\n           3066                0             0\n"
     ]
    }
   ],
   "source": [
    "# Load model using alias\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"models:/{MODEL_NAME}@Champion\")\n",
    "\n",
    "print(\"✓ Model loaded from registry using 'Champion' alias\")\n",
    "\n",
    "# Make sample predictions\n",
    "sample_data = X_test.head(5)\n",
    "predictions = loaded_model.predict(sample_data)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "prediction_df = pd.DataFrame({\n",
    "    'Customer_Index': sample_data.index,\n",
    "    'Predicted_Churn': predictions,\n",
    "    'Actual_Churn': y_test.iloc[:5].values\n",
    "})\n",
    "print(prediction_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4456001d-f57c-4a45-be6e-0a0faf7e09e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Simulate Model Version Updates\n",
    "\n",
    "In real scenarios, you'll train improved models over time. Let's simulate this by:\n",
    "1. Training an improved Random Forest model (v2)\n",
    "2. Registering it as a new version\n",
    "3. Setting it as \"Challenger\" for A/B testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54d29699-f6bb-48c2-8098-d2856b364efa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training improved Random Forest model (v2)...\n\nTraining Random_Forest_v2_Improved...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 00:08:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n\uD83D\uDD17 View Logged Model at: https://adb-3141834805281315.15.azuredatabricks.net/ml/experiments/3522400443005898/models/m-85978405114a4102800b5586d3248099?o=3141834805281315\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random_Forest_v2_Improved training complete\n  Run ID: 0df793061be34fd780b162930bea1f3e\n  Metrics: {'train_accuracy': 0.965, 'test_accuracy': 0.8025, 'test_precision': 0.5714285714285714, 'test_recall': 0.14634146341463414, 'test_f1': 0.23300970873786409, 'test_auc': np.float64(0.7655023776652861)}\n"
     ]
    }
   ],
   "source": [
    "# Train improved Random Forest with better hyperparameters\n",
    "rf_v2_params = {\n",
    "    'n_estimators': 200,  # Increased from 100\n",
    "    'max_depth': 15,      # Increased from 10\n",
    "    'min_samples_split': 3,  # Decreased from 5\n",
    "    'min_samples_leaf': 1,   # Decreased from 2\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "print(\"Training improved Random Forest model (v2)...\")\n",
    "rf_v2_model = RandomForestClassifier(**rf_v2_params)\n",
    "rf_v2_metrics, rf_v2_run_id = train_and_log_model(\n",
    "    rf_v2_model,\n",
    "    \"Random_Forest_v2_Improved\",\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    rf_v2_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c016e3b5-c1cf-461d-a7e7-726e2c199bdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering improved model as new version...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'financial_services.churn_models.customer_churn_model' already exists. Creating a new version of this model...\n2025/10/06 00:08:28 WARNING mlflow.tracking._model_registry.fluent: Run with id 0df793061be34fd780b162930bea1f3e has no artifacts at artifact path 'model', registering model based on models:/m-85978405114a4102800b5586d3248099 instead\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a2f7ae20da487b96630dfdb32f8375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d702d335677429ba1c45871547d220f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 Created version '40' of model 'financial_services.churn_models.customer_churn_model': https://adb-3141834805281315.15.azuredatabricks.net/explore/data/models/financial_services/churn_models/customer_churn_model/version/40?o=3141834805281315\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New model version registered: 40\n✓ Model version 40 set as 'Challenger'\n  Ready for A/B testing against Champion model\n"
     ]
    }
   ],
   "source": [
    "# Register the new version\n",
    "print(\"Registering improved model as new version...\")\n",
    "\n",
    "model_version_v2 = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{rf_v2_run_id}/model\",\n",
    "    name=MODEL_NAME,\n",
    "    tags={\n",
    "        \"model_type\": \"Random Forest\",\n",
    "        \"training_date\": datetime.now().strftime('%Y-%m-%d'),\n",
    "        \"use_case\": \"customer_churn_prediction\",\n",
    "        \"version_notes\": \"Improved hyperparameters for better performance\",\n",
    "        \"department\": \"data_science\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✓ New model version registered: {model_version_v2.version}\")\n",
    "\n",
    "# Set as Challenger for A/B testing\n",
    "client.set_registered_model_alias(\n",
    "    name=MODEL_NAME,\n",
    "    alias=\"Challenger\",\n",
    "    version=model_version_v2.version\n",
    ")\n",
    "\n",
    "print(f\"✓ Model version {model_version_v2.version} set as 'Challenger'\")\n",
    "print(f\"  Ready for A/B testing against Champion model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5279f9a-d449-413d-9e56-8b31eb9074ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### View All Model Versions\n",
    "\n",
    "Let's examine all versions of our registered model and their aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23e7881d-16a5-4fdb-be9b-e3e034829c7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All Versions of financial_services.churn_models.customer_churn_model ===\n\nVersion: 40\n  Run ID: 0df793061be34fd780b162930bea1f3e\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759709309794\n\nVersion: 39\n  Run ID: 6ee2b020387b4659b4271c72a1b1bc50\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759709294552\n\nVersion: 38\n  Run ID: ebb94dc6b7f54c128f47bd62d8b37002\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759708150974\n\nVersion: 37\n  Run ID: c2df7f1504fb4bca92325fc13aa8bb36\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759708136633\n\nVersion: 36\n  Run ID: e2140c052de645d0a3f4f06bf6e27681\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759707411942\n\nVersion: 35\n  Run ID: 68afd700ad614b96a1265a4b753f73dc\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759707398008\n\nVersion: 34\n  Run ID: 85ef9755f5974dedba1cd24a3ad12c7d\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759706842345\n\nVersion: 33\n  Run ID: 143c7aaacb924a5ea39b2a8190221a41\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759706828216\n\nVersion: 32\n  Run ID: 334ebaf7e6e54e2ca36750cccc1bf3dc\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759706131779\n\nVersion: 31\n  Run ID: 4a05364687284fb28a1b4adb4f4475f7\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759706118528\n\nVersion: 30\n  Run ID: c9b8269863304db7be6bc060411a9d43\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759705810607\n\nVersion: 29\n  Run ID: 066ca854ff074770b4b52fd5b9f28598\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759705796073\n\nVersion: 28\n  Run ID: 142d0e7e20bf4421ae713a8f38833a1f\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759705262305\n\nVersion: 27\n  Run ID: 0a78355cec154fc388b9132da7b6188f\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759705248442\n\nVersion: 26\n  Run ID: 1c01cc418f8b417fa9b470bf8e08ae59\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759705138796\n\nVersion: 25\n  Run ID: 8a2376f21aa64dd28c05ef20077258d4\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759705124707\n\nVersion: 24\n  Run ID: 50849f9798e44865b2e77e487e7bdb0c\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759704634347\n\nVersion: 23\n  Run ID: 88922e2e5e8d4284814c003531a8df52\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759704616255\n\nVersion: 22\n  Run ID: 360ded385a634aad8290c0259c9a6957\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759700451029\n\nVersion: 21\n  Run ID: d3e5a4ce357d4e929d8596c4758e670e\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759700436866\n\nVersion: 20\n  Run ID: 8c44d022af6a4b199329dad1918ecb91\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759699714839\n\nVersion: 19\n  Run ID: dd6d9c3b4d544853a229d44493f15e62\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759699699681\n\nVersion: 18\n  Run ID: f8d643fb15f742ffa0ba2a4ea36db19d\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759699043101\n\nVersion: 17\n  Run ID: a0c8657c529c4a8eb1d1ab8433f0336a\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759699028786\n\nVersion: 16\n  Run ID: b904fc8178174d7cb0a62c2f4b125d05\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759698214865\n\nVersion: 15\n  Run ID: d6fc01cb7b1e4af4937670f59f7ac7d3\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759698201159\n\nVersion: 14\n  Run ID: fab5536dbff34ace89c7fa189687351b\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759697448329\n\nVersion: 13\n  Run ID: 8a05450f483a49199cf5e08439900db7\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759697431755\n\nVersion: 12\n  Run ID: 1015c1f92ee748c891ef100b22b2b2c4\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759695587452\n\nVersion: 11\n  Run ID: 27eabfd3bac44259b8bc79ef1b194e06\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759695573138\n\nVersion: 10\n  Run ID: 67ff95cc00b1407584656bee62e8989d\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759694928016\n\nVersion: 9\n  Run ID: a41e81f36aab473ab2305867b0ba378c\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759694912537\n\nVersion: 8\n  Run ID: 7e654ed7c47745398272e2e40ba1cb6f\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759692861169\n\nVersion: 7\n  Run ID: 278db50a372f485aa5d0c42fd9e7e47b\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759692842226\n\nVersion: 6\n  Run ID: ffa687828d12466d892655776f2d6341\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759277279791\n\nVersion: 5\n  Run ID: 2c370330940e443aad5c1bfc2765b5ef\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759277258845\n\nVersion: 4\n  Run ID: eaff49b5027348769d5229f85269392b\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759271158129\n\nVersion: 3\n  Run ID: dc969637239d42dda82c6b7ee8db0940\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759271139327\n\nVersion: 2\n  Run ID: d04ea1b7f45e4eb382a547140e703449\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759264419152\n\nVersion: 1\n  Run ID: 0a784e905caf4f8b8bdc1e4609881be4\n  Status: READY\n  Aliases: <bound method ModelVersionSearch.aliases of <ModelVersionSearch: >>\n  Created: 1759264401554\n\n"
     ]
    }
   ],
   "source": [
    "# Get all versions of the model\n",
    "all_versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "\n",
    "print(f\"=== All Versions of {MODEL_NAME} ===\\n\")\n",
    "for version in all_versions:\n",
    "    print(f\"Version: {version.version}\")\n",
    "    print(f\"  Run ID: {version.run_id}\")\n",
    "    print(f\"  Status: {version.status}\")\n",
    "    print(f\"  Aliases: {version.aliases if hasattr(version, 'aliases') else 'None'}\")\n",
    "    print(f\"  Created: {version.creation_timestamp}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1301d857-e7a2-47e1-9c08-b9c0df708bb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 6: Unity Catalog Governance Controls\n",
    "\n",
    "Unity Catalog provides enterprise-grade governance features:\n",
    "- **RBAC (Role-Based Access Control)**: Control who can read, write, or execute models\n",
    "- **Audit Logging**: Track all operations on models and data\n",
    "- **Data Lineage**: Trace models back to training data\n",
    "\n",
    "Let's explore these governance capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ab0c1c2-6a7a-4630-95c3-2619bd86d270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Access Control with RBAC (Demonstration)\n",
    "\n",
    "Unity Catalog provides enterprise-grade access control through Role-Based Access Control (RBAC).\n",
    "\n",
    "**How RBAC Works in Production:**\n",
    "1. **Account admins** create groups at **account level** (not workspace level)\n",
    "2. **Users are added** to groups based on their roles\n",
    "3. **Permissions are granted** to groups, not individual users\n",
    "4. **Users inherit** permissions from all groups they belong to\n",
    "\n",
    "**Typical Groups in ML Projects:**\n",
    "- `data_analysts` - Read access to data tables\n",
    "- `ml_engineers` - Model execution and deployment rights\n",
    "- `data_scientists` - Full access to develop and train models\n",
    "- `data_engineers` - Data pipeline and table management\n",
    "\n",
    "**Important: Workspace vs. Account Groups**\n",
    "- Unity Catalog requires **account-level groups** (created in Account Console)\n",
    "- Workspace-level groups (created with `CREATE GROUP`) **do NOT work** with Unity Catalog\n",
    "- Only account admins can create account-level groups\n",
    "- This is a common source of confusion!\n",
    "\n",
    "**How to Create Account-Level Groups:**\n",
    "\n",
    "*Azure Databricks Account Console (UI):*\n",
    "1. Sign in to the Databricks account console (not a workspace)\n",
    "2. In Azure, go to **accounts.azuredatabricks.net** (or accounts.cloud.databricks.com for AWS/GCP)\n",
    "3. Log in as an **account admin**\n",
    "4. Navigate to the **User Management** section\n",
    "5. Select **Groups** tab\n",
    "6. Click **Add Group** button\n",
    "7. Enter group name (e.g., `ml_engineers`)\n",
    "8. Press **Add** button\n",
    "9. Repeat for all required groups: `data_analysts`, `ml_engineers`, `data_scientists`, `data_engineers`, `all_users`\n",
    "\n",
    "*Alternative - Databricks CLI:*\n",
    "```\n",
    "databricks account groups create --group-name data_analysts\n",
    "databricks account groups create --group-name ml_engineers\n",
    "databricks account groups create --group-name data_scientists\n",
    "databricks account groups create --group-name data_engineers\n",
    "databricks account groups create --group-name all_users\n",
    "```\n",
    "\n",
    "**For This Lab:**\n",
    "- If you have account-level groups, the notebook will detect and use them\n",
    "- If not, we'll demonstrate the concepts with your current user\n",
    "- Example commands show what admins would run in production\n",
    "- You'll learn the complete RBAC workflow either way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "334139bd-ba88-4b09-97ed-611f3c8fff5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking for Account-Level Groups ===\n\n⚠ Important: Unity Catalog requires ACCOUNT-LEVEL groups\n  • Workspace groups (CREATE GROUP) do NOT work with Unity Catalog\n  • Only account admins can create account-level groups\n  • Groups must be created in the Account Console\n\nRequired groups for this lab:\n  • data_analysts: Group for data analysts with read access to data\n  • ml_engineers: Group for ML engineers with model execution rights\n  • data_scientists: Group for data scientists with full schema access\n  • data_engineers: Group for data engineers with data pipeline management\n  • all_users: Group for all users with basic catalog access\n\nChecking if groups exist at account level...\n--------------------------------------------------------------------------------\n✓ data_analysts: Exists (account-level group)\n✓ ml_engineers: Exists (account-level group)\n✓ data_scientists: Exists (account-level group)\n✓ data_engineers: Exists (account-level group)\n✓ all_users: Exists (account-level group)\n\n================================================================================\nGROUP CHECK SUMMARY\n================================================================================\n\n✓ Account-level groups found: 5\n  ✓ data_analysts\n  ✓ ml_engineers\n  ✓ data_scientists\n  ✓ data_engineers\n  ✓ all_users\n\n  \uD83C\uDF89 Excellent! These groups will be used for permission grants.\n\n\uD83D\uDCCA Total available groups for permissions: 5\n  These groups will be used in the permission granting section.\n\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check if account-level groups exist\n",
    "print(\"=== Checking for Account-Level Groups ===\\n\")\n",
    "\n",
    "print(\"⚠ Important: Unity Catalog requires ACCOUNT-LEVEL groups\")\n",
    "print(\"  • Workspace groups (CREATE GROUP) do NOT work with Unity Catalog\")\n",
    "print(\"  • Only account admins can create account-level groups\")\n",
    "print(\"  • Groups must be created in the Account Console\\n\")\n",
    "\n",
    "# Define required groups\n",
    "required_groups = {\n",
    "    'data_analysts': 'Group for data analysts with read access to data',\n",
    "    'ml_engineers': 'Group for ML engineers with model execution rights',\n",
    "    'data_scientists': 'Group for data scientists with full schema access',\n",
    "    'data_engineers': 'Group for data engineers with data pipeline management',\n",
    "    'all_users': 'Group for all users with basic catalog access'\n",
    "}\n",
    "\n",
    "print(\"Required groups for this lab:\")\n",
    "for group_name, description in required_groups.items():\n",
    "    print(f\"  • {group_name}: {description}\")\n",
    "\n",
    "# Check if account-level groups exist (read-only check)\n",
    "print(\"\\nChecking if groups exist at account level...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "existing_groups = []\n",
    "missing_groups = []\n",
    "\n",
    "for group_name in required_groups.keys():\n",
    "    try:\n",
    "        # Try to grant a harmless permission to test if group exists\n",
    "        # We'll immediately revoke it, so this is just a test\n",
    "        # If group doesn't exist, this will fail with PRINCIPAL_DOES_NOT_EXIST\n",
    "        test_sql = f\"GRANT USAGE ON CATALOG {CATALOG_NAME} TO `{group_name}`\"\n",
    "        spark.sql(test_sql)\n",
    "\n",
    "        # If we got here, group exists! Now revoke the test grant\n",
    "        try:\n",
    "            spark.sql(f\"REVOKE USAGE ON CATALOG {CATALOG_NAME} FROM `{group_name}`\")\n",
    "        except:\n",
    "            pass  # Revoke might fail if already granted, that's ok\n",
    "\n",
    "        print(f\"✓ {group_name}: Exists (account-level group)\")\n",
    "        existing_groups.append(group_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e).lower()\n",
    "        if \"principal_does_not_exist\" in error_msg or \"does not exist\" in error_msg or \"cannot find\" in error_msg:\n",
    "            print(f\"⊘ {group_name}: Does not exist at account level\")\n",
    "            missing_groups.append(group_name)\n",
    "        elif \"already granted\" in error_msg or \"already has\" in error_msg:\n",
    "            # Group exists, permission was already granted\n",
    "            print(f\"✓ {group_name}: Exists (account-level group)\")\n",
    "            existing_groups.append(group_name)\n",
    "        elif \"permission\" in error_msg or \"privilege\" in error_msg:\n",
    "            # Can't verify due to permissions, but let's assume it might exist\n",
    "            print(f\"? {group_name}: Cannot verify (insufficient permissions)\")\n",
    "            print(f\"  Will attempt to use this group in permission grants\")\n",
    "            existing_groups.append(group_name)  # Optimistically add it\n",
    "        else:\n",
    "            print(f\"? {group_name}: Cannot verify ({str(e)[:80]}...)\")\n",
    "            missing_groups.append(group_name)\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GROUP CHECK SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Store available groups for later use\n",
    "available_groups = existing_groups\n",
    "\n",
    "if len(existing_groups) > 0:\n",
    "    print(f\"\\n✓ Account-level groups found: {len(existing_groups)}\")\n",
    "    for group in existing_groups:\n",
    "        print(f\"  ✓ {group}\")\n",
    "    print(\"\\n  \uD83C\uDF89 Excellent! These groups will be used for permission grants.\")\n",
    "else:\n",
    "    print(\"\\n⊘ No account-level groups found\")\n",
    "\n",
    "if len(missing_groups) > 0:\n",
    "    print(f\"\\n⊘ Groups not found: {len(missing_groups)}\")\n",
    "    for group in missing_groups:\n",
    "        print(f\"  ⊘ {group}\")\n",
    "\n",
    "    print(\"\\n\uD83D\uDCDD How to Create Account-Level Groups:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Account-level groups MUST be created in the Databricks Account Console:\")\n",
    "    print(\"\")\n",
    "    print(\"Option 1: Azure Databricks Account Console (UI) - Recommended\")\n",
    "    print(\"  1. Sign in to the Databricks account console (not a workspace)\")\n",
    "    print(\"  2. In Azure, go to: accounts.azuredatabricks.net\")\n",
    "    print(\"     (or accounts.cloud.databricks.com for AWS/GCP)\")\n",
    "    print(\"  3. Log in as an account admin\")\n",
    "    print(\"  4. Navigate to: User Management section\")\n",
    "    print(\"  5. Select: Groups tab\")\n",
    "    print(\"  6. Click: Add Group button\")\n",
    "    print(\"  7. Enter group name (e.g., ml_engineers)\")\n",
    "    print(\"  8. Press: Add button\")\n",
    "    print(\"  9. Repeat for all groups: data_analysts, ml_engineers, data_scientists,\")\n",
    "    print(\"     data_engineers, all_users\")\n",
    "    print(\"\")\n",
    "    print(\"Option 2: Databricks CLI (for Account Admins)\")\n",
    "    print(\"  databricks account groups create --group-name data_analysts\")\n",
    "    print(\"  databricks account groups create --group-name ml_engineers\")\n",
    "    print(\"  databricks account groups create --group-name data_scientists\")\n",
    "    print(\"  databricks account groups create --group-name data_engineers\")\n",
    "    print(\"  databricks account groups create --group-name all_users\")\n",
    "    print(\"\")\n",
    "    print(\"⚠ Note: CREATE GROUP in SQL creates workspace groups, NOT account groups\")\n",
    "    print(\"  Workspace groups do NOT work with Unity Catalog permissions!\")\n",
    "\n",
    "print(f\"\\n\uD83D\uDCCA Total available groups for permissions: {len(available_groups)}\")\n",
    "if len(available_groups) > 0:\n",
    "    print(\"  These groups will be used in the permission granting section.\")\n",
    "else:\n",
    "    print(\"  No groups available - will demonstrate with current user only.\")\n",
    "    print(\"  This is normal and the lab will still teach all RBAC concepts.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e35da57-71c1-46f9-867d-8583dfac7cba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Understanding Workspace vs. Account Groups\n",
    "\n",
    "**Important Distinction:**\n",
    "- `SHOW GROUPS` displays **workspace-level groups** (created with `CREATE GROUP`)\n",
    "- Unity Catalog requires **account-level groups** (created in Account Console)\n",
    "- These are **completely separate** and cannot be used interchangeably!\n",
    "\n",
    "Let's check both to understand the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27592f8c-5fd4-48fa-bf21-9f89505adc66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Understanding Group Types ===\n\n⚠ CRITICAL: Workspace Groups ≠ Account Groups\n  • SHOW GROUPS shows workspace groups\n  • Unity Catalog needs account groups\n  • They are completely separate!\n\n1. Workspace Groups (from SHOW GROUPS):\n--------------------------------------------------------------------------------\nFound 5 workspace group(s):\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>directGroup</th></tr></thead><tbody><tr><td>users</td><td>null</td></tr><tr><td>admins</td><td>null</td></tr><tr><td>ml_engineers</td><td>null</td></tr><tr><td>data_scientists</td><td>null</td></tr><tr><td>data_analysts</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "users",
         null
        ],
        [
         "admins",
         null
        ],
        [
         "ml_engineers",
         null
        ],
        [
         "data_scientists",
         null
        ],
        [
         "data_analysts",
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "directGroup",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nChecking our required groups in workspace:\n  ✓ data_analysts - Found in workspace\n  ✓ ml_engineers - Found in workspace\n  ✓ data_scientists - Found in workspace\n  ✗ data_engineers - Not in workspace\n  ✗ all_users - Not in workspace\n\n⚠ WARNING: These are WORKSPACE groups!\n  They will NOT work with Unity Catalog permissions.\n  Unity Catalog requires ACCOUNT-LEVEL groups.\n\n2. Account Groups (for Unity Catalog):\n--------------------------------------------------------------------------------\nChecking if groups exist at ACCOUNT level (required for Unity Catalog)...\n\n  ✓ data_analysts - EXISTS at account level (works with Unity Catalog)\n  ✓ ml_engineers - EXISTS at account level (works with Unity Catalog)\n  ✓ data_scientists - EXISTS at account level (works with Unity Catalog)\n  ✓ data_engineers - EXISTS at account level (works with Unity Catalog)\n  ✓ all_users - EXISTS at account level (works with Unity Catalog)\n\n================================================================================\nGROUP TYPE SUMMARY\n================================================================================\n\n\uD83D\uDCCB Workspace Groups: 5 found\n  ⚠ These do NOT work with Unity Catalog\n  ⚠ Created with: CREATE GROUP\n  ⚠ Only work for legacy workspace permissions\n\n✓ Account Groups: 5 found\n  ✓ These WORK with Unity Catalog\n    • data_analysts\n    • ml_engineers\n    • data_scientists\n    • data_engineers\n    • all_users\n\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display workspace groups vs account groups\n",
    "print(\"=== Understanding Group Types ===\\n\")\n",
    "\n",
    "print(\"⚠ CRITICAL: Workspace Groups ≠ Account Groups\")\n",
    "print(\"  • SHOW GROUPS shows workspace groups\")\n",
    "print(\"  • Unity Catalog needs account groups\")\n",
    "print(\"  • They are completely separate!\\n\")\n",
    "\n",
    "# Check workspace groups\n",
    "print(\"1. Workspace Groups (from SHOW GROUPS):\")\n",
    "print(\"-\" * 80)\n",
    "try:\n",
    "    workspace_groups = spark.sql(\"SHOW GROUPS\")\n",
    "    workspace_group_list = [row[0] for row in workspace_groups.collect()]\n",
    "\n",
    "    if len(workspace_group_list) > 0:\n",
    "        print(f\"Found {len(workspace_group_list)} workspace group(s):\")\n",
    "        display(workspace_groups)\n",
    "\n",
    "        print(\"\\nChecking our required groups in workspace:\")\n",
    "        for group_name in required_groups.keys():\n",
    "            if group_name in workspace_group_list:\n",
    "                print(f\"  ✓ {group_name} - Found in workspace\")\n",
    "            else:\n",
    "                print(f\"  ✗ {group_name} - Not in workspace\")\n",
    "\n",
    "        print(\"\\n⚠ WARNING: These are WORKSPACE groups!\")\n",
    "        print(\"  They will NOT work with Unity Catalog permissions.\")\n",
    "        print(\"  Unity Catalog requires ACCOUNT-LEVEL groups.\")\n",
    "    else:\n",
    "        print(\"No workspace groups found\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unable to list workspace groups: {str(e)}\")\n",
    "\n",
    "# Check account groups (the ones that actually work with Unity Catalog)\n",
    "print(\"\\n2. Account Groups (for Unity Catalog):\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Checking if groups exist at ACCOUNT level (required for Unity Catalog)...\\n\")\n",
    "\n",
    "account_groups_found = []\n",
    "account_groups_missing = []\n",
    "\n",
    "for group_name in required_groups.keys():\n",
    "    try:\n",
    "        # Try to grant a test permission to see if group exists\n",
    "        # This is the most reliable way to check across all Databricks versions\n",
    "        test_sql = f\"GRANT USAGE ON CATALOG {CATALOG_NAME} TO `{group_name}`\"\n",
    "        spark.sql(test_sql)\n",
    "\n",
    "        # If we got here, group exists! Revoke the test grant\n",
    "        try:\n",
    "            spark.sql(f\"REVOKE USAGE ON CATALOG {CATALOG_NAME} FROM `{group_name}`\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print(f\"  ✓ {group_name} - EXISTS at account level (works with Unity Catalog)\")\n",
    "        account_groups_found.append(group_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e).lower()\n",
    "        if \"principal_does_not_exist\" in error_msg or \"does not exist\" in error_msg or \"cannot find\" in error_msg:\n",
    "            print(f\"  ✗ {group_name} - DOES NOT EXIST at account level\")\n",
    "            account_groups_missing.append(group_name)\n",
    "        elif \"already granted\" in error_msg or \"already has\" in error_msg:\n",
    "            # Group exists, permission was already there\n",
    "            print(f\"  ✓ {group_name} - EXISTS at account level (works with Unity Catalog)\")\n",
    "            account_groups_found.append(group_name)\n",
    "        elif \"permission\" in error_msg or \"privilege\" in error_msg:\n",
    "            print(f\"  ? {group_name} - Cannot verify (insufficient permissions)\")\n",
    "            account_groups_missing.append(group_name)\n",
    "        else:\n",
    "            print(f\"  ? {group_name} - Cannot verify: {str(e)[:60]}...\")\n",
    "            account_groups_missing.append(group_name)\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GROUP TYPE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    if len(workspace_group_list) > 0:\n",
    "        print(f\"\\n\uD83D\uDCCB Workspace Groups: {len(workspace_group_list)} found\")\n",
    "        print(\"  ⚠ These do NOT work with Unity Catalog\")\n",
    "        print(\"  ⚠ Created with: CREATE GROUP\")\n",
    "        print(\"  ⚠ Only work for legacy workspace permissions\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if len(account_groups_found) > 0:\n",
    "    print(f\"\\n✓ Account Groups: {len(account_groups_found)} found\")\n",
    "    print(\"  ✓ These WORK with Unity Catalog\")\n",
    "    for group in account_groups_found:\n",
    "        print(f\"    • {group}\")\n",
    "else:\n",
    "    print(f\"\\n✗ Account Groups: 0 found\")\n",
    "    print(\"  ✗ Unity Catalog permissions will not work\")\n",
    "\n",
    "if len(account_groups_missing) > 0:\n",
    "    print(f\"\\n⊘ Missing Account Groups: {len(account_groups_missing)}\")\n",
    "    for group in account_groups_missing:\n",
    "        print(f\"    • {group}\")\n",
    "    print(\"\\n  \uD83D\uDCA1 To create account-level groups:\")\n",
    "    print(\"     1. Go to: https://accounts.cloud.databricks.com/\")\n",
    "    print(\"     2. User Management → Groups → Add Group\")\n",
    "    print(\"     3. Create each group at ACCOUNT level\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9c61d25-1aee-491b-a0a4-e6dd21b2e954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Grant Permissions (Demonstration)\n",
    "\n",
    "Unity Catalog allows fine-grained permissions. Here's how permissions would be granted in production:\n",
    "\n",
    "**Typical Permission Structure:**\n",
    "- **data_analysts**: SELECT on table (read-only access)\n",
    "- **ml_engineers**: USE SCHEMA on schema (model execution and schema access)\n",
    "- **data_scientists**: ALL PRIVILEGES on schema (full access)\n",
    "- **data_engineers**: MODIFY on table (write access for data pipelines)\n",
    "- **all_users**: USE CATALOG on catalog (basic catalog access)\n",
    "\n",
    "**Note:** This section demonstrates the concepts. In production, your admin would create groups and grant permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3140a814-dcf3-4362-b604-8669ad9d7bee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unity Catalog Permissions (Demonstration) ===\n\nCurrent user: rajaniesh@rajanieshkaushikk.com\n\nIn production, an admin would execute commands like:\n\n1. Grant read access to data analysts\n   GRANT SELECT ON TABLE financial_services.churn_models.customer_churn_data TO `data_analysts`;\n\n2. Grant schema usage to ML engineers\n   GRANT USE SCHEMA ON SCHEMA financial_services.churn_models TO `ml_engineers`;\n\n3. Grant full access to data scientists\n   GRANT ALL PRIVILEGES ON SCHEMA financial_services.churn_models TO `data_scientists`;\n\n4. Grant write access to data engineers\n   GRANT MODIFY ON TABLE financial_services.churn_models.customer_churn_data TO `data_engineers`;\n\n5. Grant catalog usage to all users\n   GRANT USE CATALOG ON CATALOG financial_services TO `all_users`;\n\n================================================================================\nAttempting to grant permissions...\n================================================================================\n\nℹ Available groups from creation section: 5\n  Groups: data_analysts, ml_engineers, data_scientists, data_engineers, all_users\n\n1. Attempting Production Group Grants:\n--------------------------------------------------------------------------------\n\nGranting SELECT on TABLE to data_analysts:\n  Object: financial_services.churn_models.customer_churn_data\n  Purpose: Read access to customer churn data\n  ✓ Status: Success - Group exists and grant applied!\n\nGranting USE SCHEMA on SCHEMA to ml_engineers:\n  Object: financial_services.churn_models\n  Purpose: Schema usage rights\n  ✓ Status: Success - Group exists and grant applied!\n\nGranting ALL PRIVILEGES on SCHEMA to data_scientists:\n  Object: financial_services.churn_models\n  Purpose: Full access to schema\n  ✓ Status: Success - Group exists and grant applied!\n\nGranting MODIFY on TABLE to data_engineers:\n  Object: financial_services.churn_models.customer_churn_data\n  Purpose: Write access to manage data pipelines\n  ✓ Status: Success - Group exists and grant applied!\n\nGranting USE CATALOG on CATALOG to all_users:\n  Object: financial_services\n  Purpose: Catalog usage rights\n  ✓ Status: Success - Group exists and grant applied!\n\n2. Granting to Current User (for demonstration):\n--------------------------------------------------------------------------------\n\nGranting SELECT on TABLE:\n  Object: financial_services.churn_models.customer_churn_data\n  ✓ Status: Success\n\nGranting USE SCHEMA on SCHEMA:\n  Object: financial_services.churn_models\n  ✓ Status: Success\n\n================================================================================\nPERMISSION GRANT SUMMARY\n================================================================================\n\n✓ Production groups successfully granted: 5\n  ✓ all_users\n  ✓ data_scientists\n  ✓ ml_engineers\n  ✓ data_analysts\n  ✓ data_engineers\n\n  \uD83C\uDF89 Excellent! Your workspace has production groups configured!\n  The verification section will show these grants.\n\n✓ Total successful grants: 5\n  - data_analysts: SELECT on TABLE\n  - ml_engineers: USE SCHEMA on SCHEMA\n  - data_scientists: ALL PRIVILEGES on SCHEMA\n  - data_engineers: MODIFY on TABLE\n  - all_users: USE CATALOG on CATALOG\n\n================================================================================\nKEY CONCEPTS - Unity Catalog Permissions\n================================================================================\n\n1. **Hierarchical Permissions**\n   - CATALOG → SCHEMA → TABLE/MODEL\n   - Permissions inherit down the hierarchy\n\n2. **Common Permission Types**\n   - USE CATALOG: Access to catalog\n   - USE SCHEMA: Access to schema\n   - SELECT: Read data from tables\n   - MODIFY: Write/update data\n   - EXECUTE: Run models/functions\n   - ALL PRIVILEGES: Full access\n\n3. **Role-Based Access Control (RBAC)**\n   - Create groups for different roles (e.g., data_analysts, ml_engineers)\n   - Grant permissions to groups, not individuals\n   - Users inherit permissions from their groups\n\n4. **Production Setup (Admin Tasks)**\n   - Create groups: CREATE GROUP data_analysts;\n   - Add users to groups: ALTER GROUP data_analysts ADD USER user@company.com;\n   - Grant permissions: GRANT SELECT ON TABLE ... TO data_analysts;\n\n5. **Best Practices**\n   - Use groups for permission management\n   - Follow principle of least privilege\n   - Document permission decisions\n   - Review permissions regularly\n   - All changes are automatically audited\n\n================================================================================\n\n✓ Permission concepts demonstrated\n\nIn production environments:\n  • Workspace admins create and manage groups\n  • Permissions are granted based on job roles\n  • All changes are tracked in audit logs\n  • Regular access reviews ensure compliance\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate permission granting concepts\n",
    "print(\"=== Unity Catalog Permissions (Demonstration) ===\\n\")\n",
    "\n",
    "# Get current user\n",
    "current_user = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "print(f\"Current user: {current_user}\\n\")\n",
    "\n",
    "# Show example permission commands\n",
    "print(\"In production, an admin would execute commands like:\\n\")\n",
    "\n",
    "example_grants = [\n",
    "    {\n",
    "        'description': 'Grant read access to data analysts',\n",
    "        'sql': f\"GRANT SELECT ON TABLE {table_path} TO `data_analysts`;\"\n",
    "    },\n",
    "    {\n",
    "        'description': 'Grant schema usage to ML engineers',\n",
    "        'sql': f\"GRANT USE SCHEMA ON SCHEMA {CATALOG_NAME}.{SCHEMA_NAME} TO `ml_engineers`;\"\n",
    "    },\n",
    "    {\n",
    "        'description': 'Grant full access to data scientists',\n",
    "        'sql': f\"GRANT ALL PRIVILEGES ON SCHEMA {CATALOG_NAME}.{SCHEMA_NAME} TO `data_scientists`;\"\n",
    "    },\n",
    "    {\n",
    "        'description': 'Grant write access to data engineers',\n",
    "        'sql': f\"GRANT MODIFY ON TABLE {table_path} TO `data_engineers`;\"\n",
    "    },\n",
    "    {\n",
    "        'description': 'Grant catalog usage to all users',\n",
    "        'sql': f\"GRANT USE CATALOG ON CATALOG {CATALOG_NAME} TO `all_users`;\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, grant in enumerate(example_grants, 1):\n",
    "    print(f\"{i}. {grant['description']}\")\n",
    "    print(f\"   {grant['sql']}\")\n",
    "    print()\n",
    "\n",
    "# Try to grant permissions to production groups (if they exist) and current user\n",
    "print(\"=\"*80)\n",
    "print(\"Attempting to grant permissions...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check if we have available_groups from earlier section\n",
    "try:\n",
    "    available_groups_list = available_groups\n",
    "    print(f\"\\nℹ Available groups from creation section: {len(available_groups_list)}\")\n",
    "    if len(available_groups_list) > 0:\n",
    "        print(f\"  Groups: {', '.join(available_groups_list)}\")\n",
    "except NameError:\n",
    "    # If available_groups doesn't exist, we'll try all groups and handle errors\n",
    "    available_groups_list = []\n",
    "    print(\"\\nℹ No group information from creation section - will attempt all groups\")\n",
    "\n",
    "successful_grants = []\n",
    "failed_grants = []\n",
    "groups_granted = []\n",
    "groups_not_found = []\n",
    "\n",
    "# Define production permissions to try\n",
    "production_permissions = [\n",
    "    {\n",
    "        'principal': 'data_analysts',\n",
    "        'privilege': 'SELECT',\n",
    "        'object_type': 'TABLE',\n",
    "        'object_name': table_path,\n",
    "        'description': 'Read access to customer churn data'\n",
    "    },\n",
    "    {\n",
    "        'principal': 'ml_engineers',\n",
    "        'privilege': 'USE SCHEMA',\n",
    "        'object_type': 'SCHEMA',\n",
    "        'object_name': f\"{CATALOG_NAME}.{SCHEMA_NAME}\",\n",
    "        'description': 'Schema usage rights'\n",
    "    },\n",
    "    {\n",
    "        'principal': 'data_scientists',\n",
    "        'privilege': 'ALL PRIVILEGES',\n",
    "        'object_type': 'SCHEMA',\n",
    "        'object_name': f\"{CATALOG_NAME}.{SCHEMA_NAME}\",\n",
    "        'description': 'Full access to schema'\n",
    "    },\n",
    "    {\n",
    "        'principal': 'data_engineers',\n",
    "        'privilege': 'MODIFY',\n",
    "        'object_type': 'TABLE',\n",
    "        'object_name': table_path,\n",
    "        'description': 'Write access to manage data pipelines'\n",
    "    },\n",
    "    {\n",
    "        'principal': 'all_users',\n",
    "        'privilege': 'USE CATALOG',\n",
    "        'object_type': 'CATALOG',\n",
    "        'object_name': CATALOG_NAME,\n",
    "        'description': 'Catalog usage rights'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Try production groups first\n",
    "print(\"\\n1. Attempting Production Group Grants:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for perm in production_permissions:\n",
    "    group_name = perm['principal']\n",
    "\n",
    "    # Skip if we know the group doesn't exist\n",
    "    if len(available_groups_list) > 0 and group_name not in available_groups_list:\n",
    "        print(f\"\\n⊘ Skipping {group_name}: Group was not created/found in earlier section\")\n",
    "        groups_not_found.append(group_name)\n",
    "        failed_grants.append(perm)\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nGranting {perm['privilege']} on {perm['object_type']} to {group_name}:\")\n",
    "    print(f\"  Object: {perm['object_name']}\")\n",
    "    print(f\"  Purpose: {perm['description']}\")\n",
    "\n",
    "    try:\n",
    "        grant_sql = f\"GRANT {perm['privilege']} ON {perm['object_type']} {perm['object_name']} TO `{group_name}`\"\n",
    "        spark.sql(grant_sql)\n",
    "        print(f\"  ✓ Status: Success - Group exists and grant applied!\")\n",
    "        successful_grants.append(perm)\n",
    "        groups_granted.append(group_name)\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"already has\" in error_msg.lower() or \"already granted\" in error_msg.lower():\n",
    "            print(f\"  ✓ Status: Already granted - Group exists!\")\n",
    "            successful_grants.append(perm)\n",
    "            groups_granted.append(group_name)\n",
    "        elif \"principal_does_not_exist\" in error_msg.lower() or \"does not exist\" in error_msg.lower() or \"cannot find\" in error_msg.lower():\n",
    "            print(f\"  ⊘ Status: Group '{group_name}' does not exist\")\n",
    "            print(f\"  Note: Group creation failed or requires account admin privileges\")\n",
    "            groups_not_found.append(group_name)\n",
    "            failed_grants.append(perm)\n",
    "        elif \"insufficient\" in error_msg.lower() or \"permission\" in error_msg.lower():\n",
    "            print(f\"  ⚠ Status: Insufficient privileges (requires admin)\")\n",
    "            print(f\"  Note: Group may exist but you need admin rights to grant\")\n",
    "            failed_grants.append(perm)\n",
    "        else:\n",
    "            print(f\"  ⚠ Status: {error_msg[:150]}...\")\n",
    "            failed_grants.append(perm)\n",
    "\n",
    "# Also grant to current user for demonstration\n",
    "print(\"\\n2. Granting to Current User (for demonstration):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "user_permissions = [\n",
    "    {\n",
    "        'principal': current_user,\n",
    "        'privilege': 'SELECT',\n",
    "        'object_type': 'TABLE',\n",
    "        'object_name': table_path,\n",
    "        'description': 'Read access to customer churn data'\n",
    "    },\n",
    "    {\n",
    "        'principal': current_user,\n",
    "        'privilege': 'USE SCHEMA',\n",
    "        'object_type': 'SCHEMA',\n",
    "        'object_name': f\"{CATALOG_NAME}.{SCHEMA_NAME}\",\n",
    "        'description': 'Schema usage rights'\n",
    "    }\n",
    "]\n",
    "\n",
    "for perm in user_permissions:\n",
    "    print(f\"\\nGranting {perm['privilege']} on {perm['object_type']}:\")\n",
    "    print(f\"  Object: {perm['object_name']}\")\n",
    "\n",
    "    try:\n",
    "        grant_sql = f\"GRANT {perm['privilege']} ON {perm['object_type']} {perm['object_name']} TO `{current_user}`\"\n",
    "        spark.sql(grant_sql)\n",
    "        print(f\"  ✓ Status: Success\")\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"already has\" in error_msg.lower() or \"already granted\" in error_msg.lower():\n",
    "            print(f\"  ✓ Status: Already granted\")\n",
    "        else:\n",
    "            print(f\"  ⚠ Status: {error_msg[:80]}...\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERMISSION GRANT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(groups_granted) > 0:\n",
    "    print(f\"\\n✓ Production groups successfully granted: {len(set(groups_granted))}\")\n",
    "    for group in set(groups_granted):\n",
    "        print(f\"  ✓ {group}\")\n",
    "    print(\"\\n  \uD83C\uDF89 Excellent! Your workspace has production groups configured!\")\n",
    "    print(\"  The verification section will show these grants.\")\n",
    "\n",
    "if len(groups_not_found) > 0:\n",
    "    print(f\"\\n⊘ Groups not found: {len(set(groups_not_found))}\")\n",
    "    for group in set(groups_not_found):\n",
    "        print(f\"  ⊘ {group}\")\n",
    "    print(\"\\n  \uD83D\uDCDD Why groups don't exist:\")\n",
    "    print(\"  • Group creation requires account admin privileges\")\n",
    "    print(\"  • You may not have permission to create groups\")\n",
    "    print(\"  • Groups may need to be created at account level\")\n",
    "    print(\"\\n  \uD83D\uDCA1 Solution:\")\n",
    "    print(\"  • Contact your Databricks account admin\")\n",
    "    print(\"  • Request creation of: data_analysts, ml_engineers, data_scientists, all_users\")\n",
    "    print(\"  • Or use this lab in demonstration mode (grants to current user)\")\n",
    "\n",
    "if successful_grants:\n",
    "    print(f\"\\n✓ Total successful grants: {len(successful_grants)}\")\n",
    "    for perm in successful_grants:\n",
    "        principal = perm.get('principal', 'current_user')\n",
    "        print(f\"  - {principal}: {perm['privilege']} on {perm['object_type']}\")\n",
    "\n",
    "if len(groups_granted) == 0:\n",
    "    print(\"\\n\uD83D\uDCCB Demonstration Mode:\")\n",
    "    print(\"  Since production groups don't exist, this lab will:\")\n",
    "    print(\"  • Grant permissions to your current user\")\n",
    "    print(\"  • Show example commands for production\")\n",
    "    print(\"  • Explain what production would look like\")\n",
    "    print(\"  • Teach RBAC concepts effectively\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY CONCEPTS - Unity Catalog Permissions\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. **Hierarchical Permissions**\n",
    "   - CATALOG → SCHEMA → TABLE/MODEL\n",
    "   - Permissions inherit down the hierarchy\n",
    "\n",
    "2. **Common Permission Types**\n",
    "   - USE CATALOG: Access to catalog\n",
    "   - USE SCHEMA: Access to schema\n",
    "   - SELECT: Read data from tables\n",
    "   - MODIFY: Write/update data\n",
    "   - EXECUTE: Run models/functions\n",
    "   - ALL PRIVILEGES: Full access\n",
    "\n",
    "3. **Role-Based Access Control (RBAC)**\n",
    "   - Create groups for different roles (e.g., data_analysts, ml_engineers)\n",
    "   - Grant permissions to groups, not individuals\n",
    "   - Users inherit permissions from their groups\n",
    "\n",
    "4. **Production Setup (Admin Tasks)**\n",
    "   - Create groups: CREATE GROUP data_analysts;\n",
    "   - Add users to groups: ALTER GROUP data_analysts ADD USER user@company.com;\n",
    "   - Grant permissions: GRANT SELECT ON TABLE ... TO data_analysts;\n",
    "\n",
    "5. **Best Practices**\n",
    "   - Use groups for permission management\n",
    "   - Follow principle of least privilege\n",
    "   - Document permission decisions\n",
    "   - Review permissions regularly\n",
    "   - All changes are automatically audited\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"\\n✓ Permission concepts demonstrated\")\n",
    "print(\"\\nIn production environments:\")\n",
    "print(\"  • Workspace admins create and manage groups\")\n",
    "print(\"  • Permissions are granted based on job roles\")\n",
    "print(\"  • All changes are tracked in audit logs\")\n",
    "print(\"  • Regular access reviews ensure compliance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6da81173-e615-4ef7-899d-576ab411cef0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Verify Granted Permissions\n",
    "\n",
    "Let's verify the permissions were granted successfully by viewing grants on each object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ded310e9-ae33-4a6c-ac37-68f2efb0f4e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Verifying Granted Permissions ===\n\nChecking what permissions exist vs. what was demonstrated...\n\n1. Table Permissions (customer_churn_data):\n--------------------------------------------------------------------------------\nExpected in production: GRANT SELECT ON TABLE ... TO `data_analysts`\n\n✓ Found 4 grant(s) on table:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Principal</th><th>ActionType</th><th>ObjectType</th><th>ObjectKey</th></tr></thead><tbody><tr><td>data_scientists</td><td>ALL PRIVILEGES</td><td>SCHEMA</td><td>financial_services.churn_models</td></tr><tr><td>data_engineers</td><td>MODIFY</td><td>TABLE</td><td>financial_services.churn_models.customer_churn_data</td></tr><tr><td>data_analysts</td><td>SELECT</td><td>TABLE</td><td>financial_services.churn_models.customer_churn_data</td></tr><tr><td>rajaniesh@rajanieshkaushikk.com</td><td>SELECT</td><td>TABLE</td><td>financial_services.churn_models.customer_churn_data</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "data_scientists",
         "ALL PRIVILEGES",
         "SCHEMA",
         "financial_services.churn_models"
        ],
        [
         "data_engineers",
         "MODIFY",
         "TABLE",
         "financial_services.churn_models.customer_churn_data"
        ],
        [
         "data_analysts",
         "SELECT",
         "TABLE",
         "financial_services.churn_models.customer_churn_data"
        ],
        [
         "rajaniesh@rajanieshkaushikk.com",
         "SELECT",
         "TABLE",
         "financial_services.churn_models.customer_churn_data"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Principal",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ActionType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ObjectType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ObjectKey",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nGrant Analysis:\n  ✓ data_analysts has SELECT permission (PRODUCTION GRANT)\n     - Row(Principal='data_analysts', ActionType='SELECT', ObjectType='TABLE', ObjectKey='financial_services.churn_models.customer_churn_data')\n  ✓ data_engineers has MODIFY permission (PRODUCTION GRANT)\n     - Row(Principal='data_engineers', ActionType='MODIFY', ObjectType='TABLE', ObjectKey='financial_services.churn_models.customer_churn_data')\n  ✓ rajaniesh@rajanieshkaushikk.com has permissions on table (DEMONSTRATION GRANT)\n     - Row(Principal='rajaniesh@rajanieshkaushikk.com', ActionType='SELECT', ObjectType='TABLE', ObjectKey='financial_services.churn_models.customer_churn_data')\n\n  \uD83D\uDCDD Note: Production groups found with correct permissions!\n\n2. Schema Permissions (churn_models):\n--------------------------------------------------------------------------------\nExpected in production:\n  • GRANT USE SCHEMA ON SCHEMA ... TO `ml_engineers`\n  • GRANT ALL PRIVILEGES ON SCHEMA ... TO `data_scientists`\n\n✓ Found 3 grant(s) on schema:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Principal</th><th>ActionType</th><th>ObjectType</th><th>ObjectKey</th></tr></thead><tbody><tr><td>data_scientists</td><td>ALL PRIVILEGES</td><td>SCHEMA</td><td>financial_services.churn_models</td></tr><tr><td>ml_engineers</td><td>USE SCHEMA</td><td>SCHEMA</td><td>financial_services.churn_models</td></tr><tr><td>rajaniesh@rajanieshkaushikk.com</td><td>USE SCHEMA</td><td>SCHEMA</td><td>financial_services.churn_models</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "data_scientists",
         "ALL PRIVILEGES",
         "SCHEMA",
         "financial_services.churn_models"
        ],
        [
         "ml_engineers",
         "USE SCHEMA",
         "SCHEMA",
         "financial_services.churn_models"
        ],
        [
         "rajaniesh@rajanieshkaushikk.com",
         "USE SCHEMA",
         "SCHEMA",
         "financial_services.churn_models"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Principal",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ActionType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ObjectType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ObjectKey",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nGrant Analysis:\n  ✓ data_scientists has ALL PRIVILEGES (PRODUCTION GRANT)\n     - Row(Principal='data_scientists', ActionType='ALL PRIVILEGES', ObjectType='SCHEMA', ObjectKey='financial_services.churn_models')\n  ✓ ml_engineers has USE SCHEMA permission (PRODUCTION GRANT)\n     - Row(Principal='ml_engineers', ActionType='USE SCHEMA', ObjectType='SCHEMA', ObjectKey='financial_services.churn_models')\n  ✓ rajaniesh@rajanieshkaushikk.com has permissions on schema (DEMONSTRATION GRANT)\n     - Row(Principal='rajaniesh@rajanieshkaushikk.com', ActionType='USE SCHEMA', ObjectType='SCHEMA', ObjectKey='financial_services.churn_models')\n\n  \uD83D\uDCDD Note: Production groups found with correct permissions!\n\n3. Catalog Permissions (financial_services):\n--------------------------------------------------------------------------------\nExpected in production: GRANT USE CATALOG ON CATALOG ... TO `all_users`\n\n✓ Found 1 grant(s) on catalog:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Principal</th><th>ActionType</th><th>ObjectType</th><th>ObjectKey</th></tr></thead><tbody><tr><td>all_users</td><td>USE CATALOG</td><td>CATALOG</td><td>financial_services</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "all_users",
         "USE CATALOG",
         "CATALOG",
         "financial_services"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Principal",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ActionType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ObjectType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ObjectKey",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nGrant Analysis:\n  ✓ all_users has USE CATALOG permission (PRODUCTION GRANT)\n     - Row(Principal='all_users', ActionType='USE CATALOG', ObjectType='CATALOG', ObjectKey='financial_services')\n\n  All grants on catalog:\n\n  \uD83D\uDCDD Note: Production group 'all_users' found with correct permissions!\n\n================================================================================\nRBAC VERIFICATION SUMMARY\n================================================================================\n\n✓ Permissions Verified:\n  - Table grants checked: financial_services.churn_models.customer_churn_data\n  - Schema grants checked: financial_services.churn_models\n  - Catalog grants checked: financial_services\n\n================================================================================\nCOMPARISON: Demonstration vs. Production\n================================================================================\n\n\uD83D\uDCCB What Was Demonstrated (Example Commands):\n--------------------------------------------------------------------------------\n1. GRANT SELECT ON TABLE ... TO `data_analysts`\n   Purpose: Read access to customer churn data\n   Status: ✓ Successfully granted!\n\n2. GRANT USE SCHEMA ON SCHEMA ... TO `ml_engineers`\n   Purpose: Schema usage rights\n   Status: ✓ Successfully granted!\n\n3. GRANT ALL PRIVILEGES ON SCHEMA ... TO `data_scientists`\n   Purpose: Full access to schema\n   Status: ✓ Successfully granted!\n\n4. GRANT USE CATALOG ON CATALOG ... TO `all_users`\n   Purpose: Catalog usage rights\n   Status: ✓ Successfully granted!\n\n\uD83D\uDCCB What Actually Exists (Verification Results):\n--------------------------------------------------------------------------------\n✓ rajaniesh@rajanieshkaushikk.com: SELECT on TABLE (demonstration grant)\n✓ rajaniesh@rajanieshkaushikk.com: USE SCHEMA on SCHEMA (demonstration grant)\n✓ data_analysts: SELECT on TABLE (production grant)\n✓ ml_engineers: USE SCHEMA on SCHEMA (production grant)\n✓ data_scientists: ALL PRIVILEGES on SCHEMA (production grant)\n✓ all_users: USE CATALOG on CATALOG (production grant)\n\n\uD83C\uDF89 Excellent! Your workspace has production groups configured and grants were successful!\n\n\uD83D\uDCCB What You Would See in Production:\n--------------------------------------------------------------------------------\n\nTable Level (customer_churn_data):\n  ✓ data_analysts: SELECT\n  ✓ data_scientists: ALL PRIVILEGES (inherited from schema)\n  ✓ ml_engineers: SELECT (if granted)\n\nSchema Level (churn_models):\n  ✓ ml_engineers: USE SCHEMA\n  ✓ data_scientists: ALL PRIVILEGES\n  ✓ data_analysts: USE SCHEMA (if granted)\n\nCatalog Level (financial_services):\n  ✓ all_users: USE CATALOG\n  ✓ admins: ALL PRIVILEGES\n  ✓ Other groups as needed\n\nEach grant would show:\n  • Principal (group name)\n  • ActionType (SELECT, USE SCHEMA, etc.)\n  • ObjectType (TABLE, SCHEMA, CATALOG)\n  • ObjectKey (full path to object)\n\n\n\uD83D\uDCCA Understanding the Results:\n--------------------------------------------------------------------------------\n\nIf you see \"No explicit grants\" or \"0 grants\", this is NORMAL and EXPECTED in:\n  • Shared Databricks workspaces\n  • Learning/training environments\n  • Workspaces with default access policies\n\nHow Access Works Without Explicit Grants:\n  1. Workspace-level permissions grant default access\n  2. Account-level permissions provide inherited access\n  3. You're the creator/owner of the objects (automatic access)\n  4. Unity Catalog uses hierarchical permission inheritance\n\nWhat This Means:\n  ✓ You CAN access and use the data/models\n  ✓ Permissions are inherited from parent levels\n  ✓ This is a secure and common configuration\n  ✓ In production, explicit grants would be added for other users/groups\n\nProduction Difference:\n  • Admins would create explicit grants for each group\n  • You would see rows in the SHOW GRANTS output\n  • Each user/group would have specific permissions listed\n  • Audit logs would track all grant operations\n\n\n================================================================================\nKEY TAKEAWAYS - Unity Catalog RBAC\n================================================================================\n\n1. ✓ Unity Catalog provides fine-grained access control\n   - Permissions at catalog, schema, table, and column levels\n   - Hierarchical inheritance of permissions\n\n2. ✓ Groups enable scalable permission management\n   - Create groups for different roles\n   - Grant permissions to groups, not individuals\n   - Users inherit from all their groups\n\n3. ✓ Production RBAC Workflow:\n   - Account admins create groups\n   - Users are assigned to groups based on roles\n   - Permissions follow principle of least privilege\n   - Regular audits ensure compliance\n\n4. ✓ All permission changes are automatically logged\n   - Complete audit trail for compliance\n   - Track who granted what to whom\n   - Query audit logs for security reviews\n\n5. ✓ RBAC is essential for enterprise governance\n   - Meets regulatory requirements\n   - Enables secure collaboration\n   - Supports data governance policies\n\nExample Production Commands:\n  CREATE GROUP data_analysts;\n  ALTER GROUP data_analysts ADD USER user@company.com;\n  GRANT SELECT ON TABLE ... TO data_analysts;\n  SHOW GRANTS ON TABLE ...;\n\n================================================================================\n\n\uD83D\uDCA1 Next Steps for Production RBAC:\n  1. Work with admin to create proper groups\n  2. Map organizational roles to Unity Catalog groups\n  3. Document permission policies\n  4. Set up regular permission audits\n  5. Train users on data access procedures\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify permissions\n",
    "print(\"=== Verifying Granted Permissions ===\\n\")\n",
    "print(\"Checking what permissions exist vs. what was demonstrated...\\n\")\n",
    "\n",
    "# Define what we expect in production\n",
    "expected_grants = {\n",
    "    'table': [\n",
    "        {'principal': 'data_analysts', 'privilege': 'SELECT', 'description': 'Read access to customer churn data'}\n",
    "    ],\n",
    "    'schema': [\n",
    "        {'principal': 'ml_engineers', 'privilege': 'USE SCHEMA', 'description': 'Schema usage rights'},\n",
    "        {'principal': 'data_scientists', 'privilege': 'ALL PRIVILEGES', 'description': 'Full access to schema'}\n",
    "    ],\n",
    "    'catalog': [\n",
    "        {'principal': 'all_users', 'privilege': 'USE CATALOG', 'description': 'Catalog usage rights'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Check table permissions\n",
    "print(\"1. Table Permissions (customer_churn_data):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Expected in production: GRANT SELECT ON TABLE ... TO `data_analysts`\\n\")\n",
    "\n",
    "try:\n",
    "    table_grants = spark.sql(f\"SHOW GRANTS ON TABLE {table_path}\")\n",
    "    grants_list = table_grants.collect()\n",
    "\n",
    "    if len(grants_list) > 0:\n",
    "        print(f\"✓ Found {len(grants_list)} grant(s) on table:\")\n",
    "        display(table_grants)\n",
    "\n",
    "        # Check for expected permissions\n",
    "        grants_text = ' '.join([str(row) for row in grants_list]).lower()\n",
    "\n",
    "        print(\"\\nGrant Analysis:\")\n",
    "\n",
    "        # Check for production groups\n",
    "        data_analysts_found = False\n",
    "        for row in grants_list:\n",
    "            row_str = str(row).lower()\n",
    "            if 'data_analysts' in row_str and 'select' in row_str:\n",
    "                print(\"  ✓ data_analysts has SELECT permission (PRODUCTION GRANT)\")\n",
    "                print(f\"     - {row}\")\n",
    "                data_analysts_found = True\n",
    "                break\n",
    "\n",
    "        if not data_analysts_found:\n",
    "            print(\"  ⊘ data_analysts: Not found (would exist in production)\")\n",
    "\n",
    "        # Check for data_engineers\n",
    "        data_engineers_found = False\n",
    "        for row in grants_list:\n",
    "            row_str = str(row).lower()\n",
    "            if 'data_engineers' in row_str and 'modify' in row_str:\n",
    "                print(\"  ✓ data_engineers has MODIFY permission (PRODUCTION GRANT)\")\n",
    "                print(f\"     - {row}\")\n",
    "                data_engineers_found = True\n",
    "                break\n",
    "\n",
    "        if not data_engineers_found:\n",
    "            print(\"  ⊘ data_engineers: Not found (would exist in production)\")\n",
    "\n",
    "        # Check for current user\n",
    "        current_user_found = False\n",
    "        for row in grants_list:\n",
    "            row_str = str(row).lower()\n",
    "            if current_user.lower() in row_str:\n",
    "                if not current_user_found:\n",
    "                    print(f\"  ✓ {current_user} has permissions on table (DEMONSTRATION GRANT)\")\n",
    "                    current_user_found = True\n",
    "                print(f\"     - {row}\")\n",
    "\n",
    "        production_groups_found = data_analysts_found or data_engineers_found\n",
    "        if production_groups_found:\n",
    "            print(\"\\n  \uD83D\uDCDD Note: Production groups found with correct permissions!\")\n",
    "        else:\n",
    "            print(\"\\n  \uD83D\uDCDD Note: In production, you would see 'data_analysts' and 'data_engineers' groups here\")\n",
    "    else:\n",
    "        print(\"⊘ No explicit grants on table\")\n",
    "        print(\"\\n\uD83D\uDCCB What You Would See in Production:\")\n",
    "        print(\"  ✓ data_analysts: SELECT permission\")\n",
    "        print(\"  ✓ Other relevant groups with appropriate permissions\")\n",
    "        print(\"\\nℹ Current Status:\")\n",
    "        print(\"  • Permissions are inherited from schema or catalog level\")\n",
    "        print(\"  • This is normal in learning environments\")\n",
    "        print(\"  • You can still access the table through inherited permissions\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unable to show table grants: {str(e)}\")\n",
    "    print(\"Note: This may be normal if grants are inherited from parent objects\")\n",
    "\n",
    "print(\"\\n2. Schema Permissions (churn_models):\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Expected in production:\")\n",
    "print(\"  • GRANT USE SCHEMA ON SCHEMA ... TO `ml_engineers`\")\n",
    "print(\"  • GRANT ALL PRIVILEGES ON SCHEMA ... TO `data_scientists`\\n\")\n",
    "\n",
    "try:\n",
    "    schema_grants = spark.sql(f\"SHOW GRANTS ON SCHEMA {CATALOG_NAME}.{SCHEMA_NAME}\")\n",
    "    grants_list = schema_grants.collect()\n",
    "\n",
    "    if len(grants_list) > 0:\n",
    "        print(f\"✓ Found {len(grants_list)} grant(s) on schema:\")\n",
    "        display(schema_grants)\n",
    "\n",
    "        # Check for expected permissions\n",
    "        grants_text = ' '.join([str(row) for row in grants_list]).lower()\n",
    "\n",
    "        print(\"\\nGrant Analysis:\")\n",
    "\n",
    "        # Check for production groups\n",
    "        ml_engineers_found = False\n",
    "        data_scientists_found = False\n",
    "\n",
    "        for row in grants_list:\n",
    "            row_str = str(row).lower()\n",
    "\n",
    "            if 'ml_engineers' in row_str and 'use schema' in row_str:\n",
    "                print(\"  ✓ ml_engineers has USE SCHEMA permission (PRODUCTION GRANT)\")\n",
    "                print(f\"     - {row}\")\n",
    "                ml_engineers_found = True\n",
    "\n",
    "            if 'data_scientists' in row_str and 'all' in row_str:\n",
    "                print(\"  ✓ data_scientists has ALL PRIVILEGES (PRODUCTION GRANT)\")\n",
    "                print(f\"     - {row}\")\n",
    "                data_scientists_found = True\n",
    "\n",
    "        if not ml_engineers_found:\n",
    "            print(\"  ⊘ ml_engineers: Not found (would exist in production)\")\n",
    "        if not data_scientists_found:\n",
    "            print(\"  ⊘ data_scientists: Not found (would exist in production)\")\n",
    "\n",
    "        # Check for current user\n",
    "        current_user_found = False\n",
    "        for row in grants_list:\n",
    "            row_str = str(row).lower()\n",
    "            if current_user.lower() in row_str:\n",
    "                if not current_user_found:\n",
    "                    print(f\"  ✓ {current_user} has permissions on schema (DEMONSTRATION GRANT)\")\n",
    "                    current_user_found = True\n",
    "                print(f\"     - {row}\")\n",
    "\n",
    "        if ml_engineers_found or data_scientists_found:\n",
    "            print(\"\\n  \uD83D\uDCDD Note: Production groups found with correct permissions!\")\n",
    "        else:\n",
    "            print(\"\\n  \uD83D\uDCDD Note: In production, you would see 'ml_engineers' and 'data_scientists' groups here\")\n",
    "    else:\n",
    "        print(\"⊘ No explicit grants on schema\")\n",
    "        print(\"\\n\uD83D\uDCCB What You Would See in Production:\")\n",
    "        print(\"  ✓ ml_engineers: USE SCHEMA permission\")\n",
    "        print(\"  ✓ data_scientists: ALL PRIVILEGES\")\n",
    "        print(\"  ✓ Other relevant groups with appropriate permissions\")\n",
    "        print(\"\\nℹ Current Status:\")\n",
    "        print(\"  • Permissions are inherited from catalog or account level\")\n",
    "        print(\"  • This is normal in shared Databricks workspaces\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unable to show schema grants: {str(e)}\")\n",
    "    print(\"Note: This may require additional permissions\")\n",
    "\n",
    "print(\"\\n3. Catalog Permissions (financial_services):\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Expected in production: GRANT USE CATALOG ON CATALOG ... TO `all_users`\\n\")\n",
    "\n",
    "try:\n",
    "    catalog_grants = spark.sql(f\"SHOW GRANTS ON CATALOG {CATALOG_NAME}\")\n",
    "    grants_list = catalog_grants.collect()\n",
    "\n",
    "    if len(grants_list) > 0:\n",
    "        print(f\"✓ Found {len(grants_list)} grant(s) on catalog:\")\n",
    "        display(catalog_grants)\n",
    "\n",
    "        # Check for expected permissions\n",
    "        grants_text = ' '.join([str(row) for row in grants_list]).lower()\n",
    "\n",
    "        print(\"\\nGrant Analysis:\")\n",
    "\n",
    "        # Check for production groups\n",
    "        all_users_found = False\n",
    "\n",
    "        for row in grants_list:\n",
    "            row_str = str(row).lower()\n",
    "            if 'all_users' in row_str and 'use catalog' in row_str:\n",
    "                print(\"  ✓ all_users has USE CATALOG permission (PRODUCTION GRANT)\")\n",
    "                print(f\"     - {row}\")\n",
    "                all_users_found = True\n",
    "\n",
    "        if not all_users_found:\n",
    "            print(\"  ⊘ all_users: Not found (would exist in production)\")\n",
    "\n",
    "        # Show all other grants\n",
    "        print(\"\\n  All grants on catalog:\")\n",
    "        for row in grants_list:\n",
    "            row_str = str(row).lower()\n",
    "            if 'all_users' not in row_str:  # Don't duplicate all_users\n",
    "                print(f\"  • {row}\")\n",
    "\n",
    "        if all_users_found:\n",
    "            print(\"\\n  \uD83D\uDCDD Note: Production group 'all_users' found with correct permissions!\")\n",
    "        else:\n",
    "            print(\"\\n  \uD83D\uDCDD Note: In production, you would see 'all_users' group here\")\n",
    "    else:\n",
    "        print(\"⊘ No explicit grants on catalog\")\n",
    "        print(\"\\n\uD83D\uDCCB What You Would See in Production:\")\n",
    "        print(\"  ✓ all_users: USE CATALOG permission\")\n",
    "        print(\"  ✓ Admin groups with full privileges\")\n",
    "        print(\"  ✓ Other relevant groups with appropriate permissions\")\n",
    "        print(\"\\nℹ Current Status:\")\n",
    "        print(\"  • Permissions are managed at account level\")\n",
    "        print(\"  • Users have default workspace access\")\n",
    "        print(\"  • Catalog is accessible to all workspace users\")\n",
    "        print(\"\\n✓ You can still use the catalog - access is inherited from workspace/account level\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unable to show catalog grants: {str(e)}\")\n",
    "    print(\"Note: This may require additional permissions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RBAC VERIFICATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Summary of what was verified\n",
    "print(\"\\n✓ Permissions Verified:\")\n",
    "print(f\"  - Table grants checked: {table_path}\")\n",
    "print(f\"  - Schema grants checked: {CATALOG_NAME}.{SCHEMA_NAME}\")\n",
    "print(f\"  - Catalog grants checked: {CATALOG_NAME}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: Demonstration vs. Production\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check what was actually granted by reviewing the grants\n",
    "try:\n",
    "    table_check = spark.sql(f\"SHOW GRANTS ON TABLE {table_path}\").collect()\n",
    "    schema_check = spark.sql(f\"SHOW GRANTS ON SCHEMA {CATALOG_NAME}.{SCHEMA_NAME}\").collect()\n",
    "    catalog_check = spark.sql(f\"SHOW GRANTS ON CATALOG {CATALOG_NAME}\").collect()\n",
    "\n",
    "    # Determine which groups were found\n",
    "    all_grants_text = ' '.join([str(row) for row in table_check + schema_check + catalog_check]).lower()\n",
    "\n",
    "    data_analysts_exists = 'data_analysts' in all_grants_text\n",
    "    ml_engineers_exists = 'ml_engineers' in all_grants_text\n",
    "    data_scientists_exists = 'data_scientists' in all_grants_text\n",
    "    all_users_exists = 'all_users' in all_grants_text\n",
    "\n",
    "except:\n",
    "    data_analysts_exists = False\n",
    "    ml_engineers_exists = False\n",
    "    data_scientists_exists = False\n",
    "    all_users_exists = False\n",
    "\n",
    "print(\"\\n\uD83D\uDCCB What Was Demonstrated (Example Commands):\")\n",
    "print(\"-\" * 80)\n",
    "print(\"1. GRANT SELECT ON TABLE ... TO `data_analysts`\")\n",
    "print(\"   Purpose: Read access to customer churn data\")\n",
    "print(f\"   Status: {'✓ Successfully granted!' if data_analysts_exists else '⊘ Group does not exist in this environment'}\")\n",
    "print(\"\")\n",
    "print(\"2. GRANT USE SCHEMA ON SCHEMA ... TO `ml_engineers`\")\n",
    "print(\"   Purpose: Schema usage rights\")\n",
    "print(f\"   Status: {'✓ Successfully granted!' if ml_engineers_exists else '⊘ Group does not exist in this environment'}\")\n",
    "print(\"\")\n",
    "print(\"3. GRANT ALL PRIVILEGES ON SCHEMA ... TO `data_scientists`\")\n",
    "print(\"   Purpose: Full access to schema\")\n",
    "print(f\"   Status: {'✓ Successfully granted!' if data_scientists_exists else '⊘ Group does not exist in this environment'}\")\n",
    "print(\"\")\n",
    "print(\"4. GRANT USE CATALOG ON CATALOG ... TO `all_users`\")\n",
    "print(\"   Purpose: Catalog usage rights\")\n",
    "print(f\"   Status: {'✓ Successfully granted!' if all_users_exists else '⊘ Group does not exist in this environment'}\")\n",
    "\n",
    "print(\"\\n\uD83D\uDCCB What Actually Exists (Verification Results):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"✓ {current_user}: SELECT on TABLE (demonstration grant)\")\n",
    "print(f\"✓ {current_user}: USE SCHEMA on SCHEMA (demonstration grant)\")\n",
    "\n",
    "if data_analysts_exists:\n",
    "    print(\"✓ data_analysts: SELECT on TABLE (production grant)\")\n",
    "else:\n",
    "    print(\"⊘ data_analysts: Not found (would exist in production)\")\n",
    "\n",
    "if ml_engineers_exists:\n",
    "    print(\"✓ ml_engineers: USE SCHEMA on SCHEMA (production grant)\")\n",
    "else:\n",
    "    print(\"⊘ ml_engineers: Not found (would exist in production)\")\n",
    "\n",
    "if data_scientists_exists:\n",
    "    print(\"✓ data_scientists: ALL PRIVILEGES on SCHEMA (production grant)\")\n",
    "else:\n",
    "    print(\"⊘ data_scientists: Not found (would exist in production)\")\n",
    "\n",
    "if all_users_exists:\n",
    "    print(\"✓ all_users: USE CATALOG on CATALOG (production grant)\")\n",
    "else:\n",
    "    print(\"⊘ all_users: Not found (would exist in production)\")\n",
    "\n",
    "# Summary message\n",
    "if data_analysts_exists or ml_engineers_exists or data_scientists_exists or all_users_exists:\n",
    "    print(\"\\n\uD83C\uDF89 Excellent! Your workspace has production groups configured and grants were successful!\")\n",
    "else:\n",
    "    print(\"\\nℹ Note: This is a learning environment without pre-configured production groups.\")\n",
    "\n",
    "print(\"\\n\uD83D\uDCCB What You Would See in Production:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\"\"\n",
    "Table Level (customer_churn_data):\n",
    "  ✓ data_analysts: SELECT\n",
    "  ✓ data_scientists: ALL PRIVILEGES (inherited from schema)\n",
    "  ✓ ml_engineers: SELECT (if granted)\n",
    "\n",
    "Schema Level (churn_models):\n",
    "  ✓ ml_engineers: USE SCHEMA\n",
    "  ✓ data_scientists: ALL PRIVILEGES\n",
    "  ✓ data_analysts: USE SCHEMA (if granted)\n",
    "\n",
    "Catalog Level (financial_services):\n",
    "  ✓ all_users: USE CATALOG\n",
    "  ✓ admins: ALL PRIVILEGES\n",
    "  ✓ Other groups as needed\n",
    "\n",
    "Each grant would show:\n",
    "  • Principal (group name)\n",
    "  • ActionType (SELECT, USE SCHEMA, etc.)\n",
    "  • ObjectType (TABLE, SCHEMA, CATALOG)\n",
    "  • ObjectKey (full path to object)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\uD83D\uDCCA Understanding the Results:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\"\"\n",
    "If you see \"No explicit grants\" or \"0 grants\", this is NORMAL and EXPECTED in:\n",
    "  • Shared Databricks workspaces\n",
    "  • Learning/training environments\n",
    "  • Workspaces with default access policies\n",
    "\n",
    "How Access Works Without Explicit Grants:\n",
    "  1. Workspace-level permissions grant default access\n",
    "  2. Account-level permissions provide inherited access\n",
    "  3. You're the creator/owner of the objects (automatic access)\n",
    "  4. Unity Catalog uses hierarchical permission inheritance\n",
    "\n",
    "What This Means:\n",
    "  ✓ You CAN access and use the data/models\n",
    "  ✓ Permissions are inherited from parent levels\n",
    "  ✓ This is a secure and common configuration\n",
    "  ✓ In production, explicit grants would be added for other users/groups\n",
    "\n",
    "Production Difference:\n",
    "  • Admins would create explicit grants for each group\n",
    "  • You would see rows in the SHOW GRANTS output\n",
    "  • Each user/group would have specific permissions listed\n",
    "  • Audit logs would track all grant operations\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY TAKEAWAYS - Unity Catalog RBAC\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. ✓ Unity Catalog provides fine-grained access control\n",
    "   - Permissions at catalog, schema, table, and column levels\n",
    "   - Hierarchical inheritance of permissions\n",
    "\n",
    "2. ✓ Groups enable scalable permission management\n",
    "   - Create groups for different roles\n",
    "   - Grant permissions to groups, not individuals\n",
    "   - Users inherit from all their groups\n",
    "\n",
    "3. ✓ Production RBAC Workflow:\n",
    "   - Account admins create groups\n",
    "   - Users are assigned to groups based on roles\n",
    "   - Permissions follow principle of least privilege\n",
    "   - Regular audits ensure compliance\n",
    "\n",
    "4. ✓ All permission changes are automatically logged\n",
    "   - Complete audit trail for compliance\n",
    "   - Track who granted what to whom\n",
    "   - Query audit logs for security reviews\n",
    "\n",
    "5. ✓ RBAC is essential for enterprise governance\n",
    "   - Meets regulatory requirements\n",
    "   - Enables secure collaboration\n",
    "   - Supports data governance policies\n",
    "\n",
    "Example Production Commands:\n",
    "  CREATE GROUP data_analysts;\n",
    "  ALTER GROUP data_analysts ADD USER user@company.com;\n",
    "  GRANT SELECT ON TABLE ... TO data_analysts;\n",
    "  SHOW GRANTS ON TABLE ...;\n",
    "\"\"\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\uD83D\uDCA1 Next Steps for Production RBAC:\")\n",
    "print(\"  1. Work with admin to create proper groups\")\n",
    "print(\"  2. Map organizational roles to Unity Catalog groups\")\n",
    "print(\"  3. Document permission policies\")\n",
    "print(\"  4. Set up regular permission audits\")\n",
    "print(\"  5. Train users on data access procedures\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cf62947-8fd0-4233-81da-7cd5cc610a57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Audit Logging\n",
    "\n",
    "Unity Catalog automatically logs all operations. Let's query the audit logs to see model operations.\n",
    "\n",
    "**Compliance Value:** Audit logs provide a complete trail for regulatory requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ad092c9-2ad3-433d-9f28-49c54d0fdbe2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Audit Logging Demonstration ===\n\nChecking audit log access...\n✓ System catalog is accessible\n\n--------------------------------------------------------------------------------\n\nQuerying audit logs for recent operations...\n(This may take a moment...)\n\nTrying: Unity Catalog operations in this session...\n✓ Found 20 audit log entries!\n\nShowing: Unity Catalog operations in this session\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>event_time</th><th>user</th><th>action_name</th><th>object_name</th><th>status_code</th></tr></thead><tbody><tr><td>2025-10-05T23:54:29.095Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getCatalog</td><td>null</td><td>200</td></tr><tr><td>2025-10-05T23:54:29.064Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getSchema</td><td>samples.nyctaxi</td><td>200</td></tr><tr><td>2025-10-05T23:54:29.064Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getSchema</td><td>samples.tpch</td><td>200</td></tr><tr><td>2025-10-05T23:49:28.451Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getRegisteredModel</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:28.437Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>listModelVersions</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:28.225Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getRegisteredModel</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:28.113Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getRegisteredModel</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:27.942Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getRegisteredModel</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:27.567Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getRegisteredModel</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:19.145Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getCatalog</td><td>null</td><td>200</td></tr><tr><td>2025-10-05T23:49:12.523Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getRegisteredModel</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:12.511Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>listModelVersions</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:12.419Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>setRegisteredModelAlias</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:12.341Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getRegisteredModel</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:12.021Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getRegisteredModel</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:11.995Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>finalizeModelVersion</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:49:11.049Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getRegisteredModel</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:48:59.403Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getModelVersion</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:48:59.348Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getRegisteredModel</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr><tr><td>2025-10-05T23:48:59.163Z</td><td>rajaniesh@rajanieshkaushikk.com</td><td>getRegisteredModel</td><td>financial_services.churn_models.customer_churn_model</td><td>200</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2025-10-05T23:54:29.095Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getCatalog",
         null,
         200
        ],
        [
         "2025-10-05T23:54:29.064Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getSchema",
         "samples.nyctaxi",
         200
        ],
        [
         "2025-10-05T23:54:29.064Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getSchema",
         "samples.tpch",
         200
        ],
        [
         "2025-10-05T23:49:28.451Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getRegisteredModel",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:28.437Z",
         "rajaniesh@rajanieshkaushikk.com",
         "listModelVersions",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:28.225Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getRegisteredModel",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:28.113Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getRegisteredModel",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:27.942Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getRegisteredModel",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:27.567Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getRegisteredModel",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:19.145Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getCatalog",
         null,
         200
        ],
        [
         "2025-10-05T23:49:12.523Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getRegisteredModel",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:12.511Z",
         "rajaniesh@rajanieshkaushikk.com",
         "listModelVersions",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:12.419Z",
         "rajaniesh@rajanieshkaushikk.com",
         "setRegisteredModelAlias",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:12.341Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getRegisteredModel",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:12.021Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getRegisteredModel",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:11.995Z",
         "rajaniesh@rajanieshkaushikk.com",
         "finalizeModelVersion",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:49:11.049Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getRegisteredModel",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:48:59.403Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getModelVersion",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:48:59.348Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getRegisteredModel",
         "financial_services.churn_models.customer_churn_model",
         200
        ],
        [
         "2025-10-05T23:48:59.163Z",
         "rajaniesh@rajanieshkaushikk.com",
         "getRegisteredModel",
         "financial_services.churn_models.customer_churn_model",
         200
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\":\"Timestamp of the event\"}",
         "name": "event_time",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "user",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"The name of the action that has been performed as part of the audit event. Action names vary depending on the Databricks service (service_name). See [documentation of actions per service](https://learn.microsoft.com/azure/databricks/admin/account-settings/audit-logs) for details.\"}",
         "name": "action_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "object_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "status_code",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\nAUDIT LOG ANALYSIS\n================================================================================\n\n✓ Successfully retrieved audit logs from Unity Catalog\n\nWhat These Logs Show:\n  • event_time: When the operation occurred\n  • user: Who performed the operation (rajaniesh@rajanieshkaushikk.com)\n  • action_name: What operation was performed (createTable, getTable, etc.)\n  • object_name: Which object was accessed\n  • status_code: Success (200) or error codes\n\nCompliance Value:\n  ✓ Complete audit trail of all operations\n  ✓ Track who accessed what data and when\n  ✓ Investigate security incidents\n  ✓ Meet regulatory requirements (SOX, GDPR, HIPAA)\n  ✓ Generate compliance reports\n\n"
     ]
    }
   ],
   "source": [
    "# Query audit logs for model operations\n",
    "print(\"=== Audit Logging Demonstration ===\\n\")\n",
    "\n",
    "# Check if system catalog is accessible\n",
    "print(\"Checking audit log access...\")\n",
    "audit_available = False\n",
    "\n",
    "try:\n",
    "    # Try to access system catalog\n",
    "    spark.sql(\"USE CATALOG system\")\n",
    "    spark.sql(\"SHOW TABLES IN system.access\").collect()\n",
    "    audit_available = True\n",
    "    print(\"✓ System catalog is accessible\")\n",
    "except Exception as e:\n",
    "    print(\"⚠ System catalog not accessible in this workspace\")\n",
    "    print(f\"  Reason: {str(e)[:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "\n",
    "if audit_available:\n",
    "    print(\"\\nQuerying audit logs for recent operations...\")\n",
    "    print(\"(This may take a moment...)\\n\")\n",
    "\n",
    "    # Try multiple queries to find audit data\n",
    "    queries_to_try = [\n",
    "        {\n",
    "            'name': 'Unity Catalog operations in this session',\n",
    "            'query': f\"\"\"\n",
    "                SELECT\n",
    "                    event_time,\n",
    "                    user_identity.email as user,\n",
    "                    action_name,\n",
    "                    request_params.full_name_arg as object_name,\n",
    "                    response.status_code\n",
    "                FROM system.access.audit\n",
    "                WHERE event_date >= current_date() - INTERVAL 1 DAY\n",
    "                    AND user_identity.email = '{current_user}'\n",
    "                    AND (\n",
    "                        action_name IN ('createTable', 'createSchema', 'createCatalog',\n",
    "                                       'getTable', 'getSchema', 'getCatalog',\n",
    "                                       'createRegisteredModelVersion', 'updateRegisteredModel')\n",
    "                        OR request_params.full_name_arg LIKE '%{CATALOG_NAME}%'\n",
    "                        OR request_params.full_name_arg LIKE '%{SCHEMA_NAME}%'\n",
    "                    )\n",
    "                ORDER BY event_time DESC\n",
    "                LIMIT 20\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            'name': 'Recent table operations',\n",
    "            'query': f\"\"\"\n",
    "                SELECT\n",
    "                    event_time,\n",
    "                    user_identity.email as user,\n",
    "                    action_name,\n",
    "                    request_params.full_name_arg as object_name\n",
    "                FROM system.access.audit\n",
    "                WHERE event_date >= current_date() - INTERVAL 1 DAY\n",
    "                    AND action_name IN ('createTable', 'getTable', 'readTable')\n",
    "                ORDER BY event_time DESC\n",
    "                LIMIT 10\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            'name': 'Any recent operations by current user',\n",
    "            'query': f\"\"\"\n",
    "                SELECT\n",
    "                    event_time,\n",
    "                    user_identity.email as user,\n",
    "                    action_name,\n",
    "                    request_params.full_name_arg as object_name\n",
    "                FROM system.access.audit\n",
    "                WHERE event_date >= current_date()\n",
    "                    AND user_identity.email = '{current_user}'\n",
    "                ORDER BY event_time DESC\n",
    "                LIMIT 10\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    audit_found = False\n",
    "\n",
    "    for query_info in queries_to_try:\n",
    "        if audit_found:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            print(f\"Trying: {query_info['name']}...\")\n",
    "            audit_logs = spark.sql(query_info['query'])\n",
    "            audit_count = audit_logs.count()\n",
    "\n",
    "            if audit_count > 0:\n",
    "                print(f\"✓ Found {audit_count} audit log entries!\\n\")\n",
    "                print(f\"Showing: {query_info['name']}\")\n",
    "                display(audit_logs)\n",
    "                audit_found = True\n",
    "\n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(\"AUDIT LOG ANALYSIS\")\n",
    "                print(\"=\"*80)\n",
    "                print(f\"\"\"\n",
    "✓ Successfully retrieved audit logs from Unity Catalog\n",
    "\n",
    "What These Logs Show:\n",
    "  • event_time: When the operation occurred\n",
    "  • user: Who performed the operation ({current_user})\n",
    "  • action_name: What operation was performed (createTable, getTable, etc.)\n",
    "  • object_name: Which object was accessed\n",
    "  • status_code: Success (200) or error codes\n",
    "\n",
    "Compliance Value:\n",
    "  ✓ Complete audit trail of all operations\n",
    "  ✓ Track who accessed what data and when\n",
    "  ✓ Investigate security incidents\n",
    "  ✓ Meet regulatory requirements (SOX, GDPR, HIPAA)\n",
    "  ✓ Generate compliance reports\n",
    "\"\"\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"  No results for this query\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Query failed: {str(e)[:80]}...\")\n",
    "            continue\n",
    "\n",
    "    if not audit_found:\n",
    "        print(\"\\n⚠ No audit logs found with any query\")\n",
    "        print(\"\\nPossible reasons:\")\n",
    "        print(\"  • Audit logs may have a delay before appearing (up to 1 hour)\")\n",
    "        print(\"  • Logs may be retained for limited time\")\n",
    "        print(\"  • Some operations may not be logged in this workspace type\")\n",
    "        print(\"  • Filters may not match recent operations\")\n",
    "        audit_available = False\n",
    "\n",
    "if not audit_available:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AUDIT LOG DEMONSTRATION (Simulated)\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nSince audit logs aren't available, here's what they would show for this lab:\\n\")\n",
    "\n",
    "    # Create simulated audit log data\n",
    "    from datetime import datetime, timedelta\n",
    "    import pandas as pd\n",
    "\n",
    "    current_time = datetime.now()\n",
    "\n",
    "    simulated_logs = [\n",
    "        {\n",
    "            'event_time': (current_time - timedelta(minutes=10)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'user': current_user,\n",
    "            'action_name': 'createCatalog',\n",
    "            'object_name': CATALOG_NAME,\n",
    "            'status_code': 200\n",
    "        },\n",
    "        {\n",
    "            'event_time': (current_time - timedelta(minutes=9)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'user': current_user,\n",
    "            'action_name': 'createSchema',\n",
    "            'object_name': f'{CATALOG_NAME}.{SCHEMA_NAME}',\n",
    "            'status_code': 200\n",
    "        },\n",
    "        {\n",
    "            'event_time': (current_time - timedelta(minutes=8)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'user': current_user,\n",
    "            'action_name': 'createTable',\n",
    "            'object_name': table_path,\n",
    "            'status_code': 200\n",
    "        },\n",
    "        {\n",
    "            'event_time': (current_time - timedelta(minutes=5)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'user': current_user,\n",
    "            'action_name': 'createRegisteredModelVersion',\n",
    "            'object_name': MODEL_NAME,\n",
    "            'status_code': 200\n",
    "        },\n",
    "        {\n",
    "            'event_time': (current_time - timedelta(minutes=3)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'user': current_user,\n",
    "            'action_name': 'setRegisteredModelAlias',\n",
    "            'object_name': f'{MODEL_NAME} (Champion)',\n",
    "            'status_code': 200\n",
    "        },\n",
    "        {\n",
    "            'event_time': (current_time - timedelta(minutes=2)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'user': current_user,\n",
    "            'action_name': 'grantPrivileges',\n",
    "            'object_name': f'USE SCHEMA on {CATALOG_NAME}.{SCHEMA_NAME}',\n",
    "            'status_code': 200\n",
    "        },\n",
    "        {\n",
    "            'event_time': (current_time - timedelta(minutes=1)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'user': current_user,\n",
    "            'action_name': 'getTable',\n",
    "            'object_name': table_path,\n",
    "            'status_code': 200\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    simulated_df = pd.DataFrame(simulated_logs)\n",
    "    print(\"Simulated Audit Log Entries (What Would Appear in Production):\")\n",
    "    print(\"-\"*80)\n",
    "    display(simulated_df)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AUDIT LOG ANALYSIS (Simulated)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\"\"\n",
    "What These Logs Show:\n",
    "  ✓ Catalog creation: {CATALOG_NAME}\n",
    "  ✓ Schema creation: {SCHEMA_NAME}\n",
    "  ✓ Table creation: {TABLE_NAME}\n",
    "  ✓ Model registration: {MODEL_NAME}\n",
    "  ✓ Model alias assignment: Champion\n",
    "  ✓ Permission grant: USE SCHEMA\n",
    "  ✓ Data access: getTable operation\n",
    "\n",
    "All operations performed by: {current_user}\n",
    "All operations successful: status_code = 200\n",
    "\n",
    "Compliance Value:\n",
    "  ✓ Complete audit trail of all operations\n",
    "  ✓ Track who accessed what data and when\n",
    "  ✓ Investigate security incidents\n",
    "  ✓ Meet regulatory requirements (SOX, GDPR, HIPAA)\n",
    "  ✓ Generate compliance reports\n",
    "  ✓ Retention: 90+ days (configurable)\n",
    "\"\"\")\n",
    "\n",
    "    print(\"\\n\uD83D\uDCDA About Unity Catalog Audit Logs:\")\n",
    "    print(\"-\"*80)\n",
    "    print(\"\"\"\n",
    "Audit logs in Unity Catalog track ALL operations including:\n",
    "\n",
    "1. **Data Access**\n",
    "   - Table reads and writes (getTable, readTable)\n",
    "   - Schema and catalog access\n",
    "   - Column-level access (if enabled)\n",
    "\n",
    "2. **Model Operations**\n",
    "   - Model registration (createRegisteredModelVersion)\n",
    "   - Version creation and updates\n",
    "   - Model alias changes (setRegisteredModelAlias)\n",
    "   - Model downloads and deployments\n",
    "\n",
    "3. **Permission Changes**\n",
    "   - GRANT and REVOKE operations (grantPrivileges, revokePrivileges)\n",
    "   - Group membership changes\n",
    "   - Role assignments\n",
    "\n",
    "4. **Administrative Actions**\n",
    "   - Catalog/schema creation (createCatalog, createSchema)\n",
    "   - Table modifications (createTable, alterTable)\n",
    "   - Policy updates\n",
    "\n",
    "Example Audit Log Query:\n",
    "\"\"\")\n",
    "\n",
    "    print(\"\"\"\n",
    "-- Query all operations on a specific model\n",
    "SELECT\n",
    "    event_time,\n",
    "    user_identity.email,\n",
    "    action_name,\n",
    "    request_params.name,\n",
    "    response.status_code\n",
    "FROM system.access.audit\n",
    "WHERE request_params.name = 'catalog.schema.model_name'\n",
    "ORDER BY event_time DESC;\n",
    "\n",
    "-- Query all permission grants\n",
    "SELECT\n",
    "    event_time,\n",
    "    user_identity.email,\n",
    "    action_name,\n",
    "    request_params.privilege,\n",
    "    request_params.principal\n",
    "FROM system.access.audit\n",
    "WHERE action_name LIKE '%GRANT%'\n",
    "ORDER BY event_time DESC;\n",
    "\n",
    "-- Query all data access\n",
    "SELECT\n",
    "    event_time,\n",
    "    user_identity.email,\n",
    "    action_name,\n",
    "    request_params.full_name_arg\n",
    "FROM system.access.audit\n",
    "WHERE action_name = 'getTable'\n",
    "ORDER BY event_time DESC;\n",
    "\"\"\")\n",
    "\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"In Production Environments:\")\n",
    "    print(\"  ✓ Audit logs are automatically enabled\")\n",
    "    print(\"  ✓ Logs are retained for 90+ days (configurable)\")\n",
    "    print(\"  ✓ Can be exported to external systems (S3, Azure, etc.)\")\n",
    "    print(\"  ✓ Used for compliance reporting and security monitoring\")\n",
    "    print(\"  ✓ Integrated with SIEM tools for real-time alerting\")\n",
    "\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"What Audit Logs Would Show for This Lab:\")\n",
    "    print(\"  • Model registration: \" + MODEL_NAME)\n",
    "    print(\"  • Version creation: Versions 1, 2, etc.\")\n",
    "    print(\"  • Alias assignments: Champion, Challenger\")\n",
    "    print(\"  • Table creation: \" + table_path)\n",
    "    print(\"  • All by user: \" + current_user)\n",
    "    print(\"  • Timestamps for each operation\")\n",
    "    print(\"  • Success/failure status codes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4b226d9-4c9f-48db-91fd-f747d51b6a35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Lineage Tracking\n",
    "\n",
    "Unity Catalog automatically tracks lineage from data to models. This shows:\n",
    "- Which tables were used to train the model\n",
    "- Which notebooks/jobs created the model\n",
    "- Downstream dependencies\n",
    "\n",
    "**Governance Benefit:** Complete transparency for auditors and stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9081067-9392-45a9-b796-752bcc03dd87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Lineage Information ===\n\nModel: financial_services.churn_models.customer_churn_model\nDescription: N/A...\n\nLineage:\n  - Source Data: financial_services.churn_models.customer_churn_data\n  - Training Notebook: /Users/rajaniesh@rajanieshkaushikk.com/churn_prediction_experiments\n  - Total Versions: 40\n  - Current Champion: Version 39\n  - Current Challenger: Version 40\n\n✓ Unity Catalog tracks complete lineage:\n  Data → Model → Deployment\n  All accessible through the Unity Catalog UI\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate lineage information\n",
    "print(\"=== Model Lineage Information ===\\n\")\n",
    "\n",
    "# Get model details\n",
    "model_details = client.get_registered_model(MODEL_NAME)\n",
    "\n",
    "print(f\"Model: {model_details.name}\")\n",
    "print(f\"Description: {model_details.description[:100] if model_details.description else 'N/A'}...\")\n",
    "print(f\"\\nLineage:\")\n",
    "print(f\"  - Source Data: {table_path}\")\n",
    "print(f\"  - Training Notebook: {experiment_name}\")\n",
    "print(f\"  - Total Versions: {len(all_versions)}\")\n",
    "print(f\"  - Current Champion: Version {model_version.version}\")\n",
    "print(f\"  - Current Challenger: Version {model_version_v2.version}\")\n",
    "\n",
    "# Show data lineage through Unity Catalog\n",
    "print(f\"\\n✓ Unity Catalog tracks complete lineage:\")\n",
    "print(f\"  Data → Model → Deployment\")\n",
    "print(f\"  All accessible through the Unity Catalog UI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e78be061-b6ee-4a7b-b95f-e312455019f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 7: Model Monitoring and Reproducibility\n",
    "\n",
    "For production models, we need:\n",
    "- **Reproducibility**: Ability to recreate any model version\n",
    "- **Monitoring**: Track model performance over time\n",
    "- **Documentation**: Clear records of all decisions\n",
    "\n",
    "Let's implement these best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9925c524-688d-47cf-af47-7acce86a250e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Reproducibility: Recreate Model from Registry\n",
    "\n",
    "Demonstrate how to fully reproduce a model using MLflow tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "523f8202-d038-4166-b9b9-62115fe92c10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Reproducibility Information ===\n\nRun ID: 6ee2b020387b4659b4271c72a1b1bc50\nExperiment ID: 3522400443005898\nStart Time: 2025-10-06 00:08:05.366000\nEnd Time: 2025-10-06 00:08:12.774000\n\nLogged Parameters:\n  learning_rate: 0.1\n  max_depth: 5\n  min_samples_leaf: 2\n  min_samples_split: 5\n  n_estimators: 100\n  random_state: 42\n\nLogged Metrics:\n  test_accuracy: 0.8030\n  test_auc: 0.7703\n  test_f1: 0.3207\n  test_precision: 0.5471\n  test_recall: 0.2268\n  train_accuracy: 0.8826\n\nLogged Tags:\n  data_version: v1.0\n  model_type: GradientBoostingClassifier\n  purpose: customer_churn_prediction\n  sparkDatasourceInfo: path=abfss:REDACTED_LOCAL_PART@transactionsmetastore.dfs.core.windows.net/root/723d09d3-f33a-4930-9f3e-5e3a6a967058/tables/afbf6737-0233-46ba-a69c-36d081aba5ab,version=19,format=delta\n  training_date: 2025-10-06\n\n✓ All information needed to reproduce this model is logged\n"
     ]
    }
   ],
   "source": [
    "# Get run information for reproducibility\n",
    "run_info = client.get_run(best_run_id)\n",
    "\n",
    "print(\"=== Model Reproducibility Information ===\\n\")\n",
    "print(f\"Run ID: {run_info.info.run_id}\")\n",
    "print(f\"Experiment ID: {run_info.info.experiment_id}\")\n",
    "print(f\"Start Time: {datetime.fromtimestamp(run_info.info.start_time/1000)}\")\n",
    "print(f\"End Time: {datetime.fromtimestamp(run_info.info.end_time/1000)}\")\n",
    "\n",
    "print(\"\\nLogged Parameters:\")\n",
    "for key, value in run_info.data.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nLogged Metrics:\")\n",
    "for key, value in run_info.data.metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nLogged Tags:\")\n",
    "for key, value in run_info.data.tags.items():\n",
    "    if not key.startswith('mlflow.'):\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n✓ All information needed to reproduce this model is logged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4410fd1-abfe-4b66-8dd4-89e5126a1e81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create Model Performance Report\n",
    "\n",
    "Generate a comprehensive report for stakeholders and compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bf39a47-3e6e-47fc-afbd-b23fea9f45a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\nCUSTOMER CHURN MODEL - PERFORMANCE REPORT\n================================================================================\n\nReport Generated: 2025-10-06 00:08:52\nModel Name: financial_services.churn_models.customer_churn_model\nChampion Version: 39\nChallenger Version: 40\n\n================================================================================\nCHAMPION MODEL PERFORMANCE\n================================================================================\n\nAlgorithm: Gradient Boosting\nTraining Samples: 8,000\nTest Samples: 2,000\nNumber of Features: 14\n\nPerformance Metrics (Test Set):\n  - Accuracy:  0.8030\n  - Precision: 0.5471\n  - Recall:    0.2268\n  - F1 Score:  0.3207\n  - AUC-ROC:   0.7703\n\n================================================================================\nCHALLENGER MODEL PERFORMANCE\n================================================================================\n\nAlgorithm: Random Forest (Improved)\nPerformance Metrics (Test Set):\n  - Accuracy:  0.8025\n  - Precision: 0.5714\n  - Recall:    0.1463\n  - F1 Score:  0.2330\n  - AUC-ROC:   0.7655\n\n================================================================================\nGOVERNANCE & COMPLIANCE\n================================================================================\n\n✓ Data stored in Unity Catalog with access controls\n✓ All experiments tracked in MLflow\n✓ Model versions registered with full documentation\n✓ Audit logs available for all operations\n✓ Complete lineage from data to deployment\n✓ RBAC implemented for data and model access\n\n================================================================================\nRECOMMENDATIONS\n================================================================================\n\n1. Deploy Champion model to production\n2. Run A/B test with Challenger model\n3. Monitor model performance weekly\n4. Retrain model quarterly with fresh data\n5. Review audit logs monthly for compliance\n\n================================================================================\n\n\n✓ Report saved to /tmp/model_performance_report.txt\n"
     ]
    }
   ],
   "source": [
    "# Create performance report\n",
    "report = f\"\"\"\n",
    "{'='*80}\n",
    "CUSTOMER CHURN MODEL - PERFORMANCE REPORT\n",
    "{'='*80}\n",
    "\n",
    "Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Model Name: {MODEL_NAME}\n",
    "Champion Version: {model_version.version}\n",
    "Challenger Version: {model_version_v2.version}\n",
    "\n",
    "{'='*80}\n",
    "CHAMPION MODEL PERFORMANCE\n",
    "{'='*80}\n",
    "\n",
    "Algorithm: {best_model_name}\n",
    "Training Samples: {X_train.shape[0]:,}\n",
    "Test Samples: {X_test.shape[0]:,}\n",
    "Number of Features: {X_train.shape[1]}\n",
    "\n",
    "Performance Metrics (Test Set):\n",
    "  - Accuracy:  {comparison_df.loc[best_model_idx, 'Accuracy']:.4f}\n",
    "  - Precision: {comparison_df.loc[best_model_idx, 'Precision']:.4f}\n",
    "  - Recall:    {comparison_df.loc[best_model_idx, 'Recall']:.4f}\n",
    "  - F1 Score:  {comparison_df.loc[best_model_idx, 'F1_Score']:.4f}\n",
    "  - AUC-ROC:   {comparison_df.loc[best_model_idx, 'AUC']:.4f}\n",
    "\n",
    "{'='*80}\n",
    "CHALLENGER MODEL PERFORMANCE\n",
    "{'='*80}\n",
    "\n",
    "Algorithm: Random Forest (Improved)\n",
    "Performance Metrics (Test Set):\n",
    "  - Accuracy:  {rf_v2_metrics['test_accuracy']:.4f}\n",
    "  - Precision: {rf_v2_metrics['test_precision']:.4f}\n",
    "  - Recall:    {rf_v2_metrics['test_recall']:.4f}\n",
    "  - F1 Score:  {rf_v2_metrics['test_f1']:.4f}\n",
    "  - AUC-ROC:   {rf_v2_metrics['test_auc']:.4f}\n",
    "\n",
    "{'='*80}\n",
    "GOVERNANCE & COMPLIANCE\n",
    "{'='*80}\n",
    "\n",
    "✓ Data stored in Unity Catalog with access controls\n",
    "✓ All experiments tracked in MLflow\n",
    "✓ Model versions registered with full documentation\n",
    "✓ Audit logs available for all operations\n",
    "✓ Complete lineage from data to deployment\n",
    "✓ RBAC implemented for data and model access\n",
    "\n",
    "{'='*80}\n",
    "RECOMMENDATIONS\n",
    "{'='*80}\n",
    "\n",
    "1. Deploy Champion model to production\n",
    "2. Run A/B test with Challenger model\n",
    "3. Monitor model performance weekly\n",
    "4. Retrain model quarterly with fresh data\n",
    "5. Review audit logs monthly for compliance\n",
    "\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report as artifact\n",
    "with open('/tmp/model_performance_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"\\n✓ Report saved to /tmp/model_performance_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bb7bc7f-0e9b-4eff-aa1a-1c445aebad72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 8: Model Archiving and Cleanup Policies\n",
    "\n",
    "As models accumulate, we need policies for:\n",
    "- **Archiving old versions** that are no longer in use\n",
    "- **Cleaning up experiments** to maintain organization\n",
    "- **Retaining compliance records** per regulatory requirements\n",
    "\n",
    "**Best Practice:** Archive models rather than delete them to maintain audit trails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33047538-7867-4a38-8ddc-ebef3dd5ca7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Archive Old Model Versions\n",
    "\n",
    "Let's demonstrate archiving a model version that's no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94e3273a-aecf-4981-a567-62faa491585b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model version 1 archived\n  Reason: Superseded by improved models with better performance\n  Date: 2025-10-06\n"
     ]
    }
   ],
   "source": [
    "# Function to archive old model versions\n",
    "def archive_model_version(model_name, version, reason):\n",
    "    \"\"\"\n",
    "    Archive a model version by adding archive tags and documentation.\n",
    "\n",
    "    Args:\n",
    "        model_name: Full model name in Unity Catalog\n",
    "        version: Version number to archive\n",
    "        reason: Reason for archiving\n",
    "    \"\"\"\n",
    "    client.set_model_version_tag(\n",
    "        name=model_name,\n",
    "        version=version,\n",
    "        key=\"archived\",\n",
    "        value=\"true\"\n",
    "    )\n",
    "\n",
    "    client.set_model_version_tag(\n",
    "        name=model_name,\n",
    "        version=version,\n",
    "        key=\"archive_date\",\n",
    "        value=datetime.now().strftime('%Y-%m-%d')\n",
    "    )\n",
    "\n",
    "    client.set_model_version_tag(\n",
    "        name=model_name,\n",
    "        version=version,\n",
    "        key=\"archive_reason\",\n",
    "        value=reason\n",
    "    )\n",
    "\n",
    "    print(f\"✓ Model version {version} archived\")\n",
    "    print(f\"  Reason: {reason}\")\n",
    "    print(f\"  Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Example: Archive the first version if we have multiple versions\n",
    "if len(all_versions) > 2:\n",
    "    archive_model_version(\n",
    "        MODEL_NAME,\n",
    "        all_versions[-1].version,  # Oldest version\n",
    "        \"Superseded by improved models with better performance\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Note: Archiving demonstration - would archive older versions in production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bc53247-70c8-4539-a187-2276f1ae58de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Cleanup Policy Implementation\n",
    "\n",
    "Define and implement cleanup policies for model registry maintenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd91aaf2-3cf7-4b66-84e5-57b52ab83072",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Registry Cleanup Policy ===\n\nRetain Champion: True\nRetain Challenger: True\nArchive After Days: 90\nMax Versions: 10\nRequire Documentation: True\n\n=== Cleanup Analysis ===\nTotal versions: 40\nArchivable versions: 0\n\n✓ No versions need archiving at this time\n"
     ]
    }
   ],
   "source": [
    "# Define cleanup policy\n",
    "cleanup_policy = {\n",
    "    'retain_champion': True,  # Always keep Champion model\n",
    "    'retain_challenger': True,  # Always keep Challenger model\n",
    "    'archive_after_days': 90,  # Archive versions older than 90 days\n",
    "    'max_versions': 10,  # Keep maximum 10 versions\n",
    "    'require_documentation': True  # All versions must have documentation\n",
    "}\n",
    "\n",
    "print(\"=== Model Registry Cleanup Policy ===\\n\")\n",
    "for key, value in cleanup_policy.items():\n",
    "    print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "# Implement cleanup check\n",
    "def check_cleanup_needed(model_name, policy):\n",
    "    \"\"\"\n",
    "    Check if cleanup is needed based on policy.\n",
    "\n",
    "    Args:\n",
    "        model_name: Full model name in Unity Catalog\n",
    "        policy: Dictionary of cleanup policies\n",
    "\n",
    "    Returns:\n",
    "        List of versions that can be archived\n",
    "    \"\"\"\n",
    "    versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "\n",
    "    # Get versions with aliases (Champion, Challenger)\n",
    "    protected_versions = set()\n",
    "    for version in versions:\n",
    "        if hasattr(version, 'aliases') and version.aliases:\n",
    "            protected_versions.add(version.version)\n",
    "\n",
    "    # Find versions that can be archived\n",
    "    archivable = []\n",
    "    for version in versions:\n",
    "        # Skip protected versions\n",
    "        if version.version in protected_versions:\n",
    "            continue\n",
    "\n",
    "        # Check age\n",
    "        created_time = datetime.fromtimestamp(version.creation_timestamp / 1000)\n",
    "        age_days = (datetime.now() - created_time).days\n",
    "\n",
    "        if age_days > policy['archive_after_days']:\n",
    "            archivable.append({\n",
    "                'version': version.version,\n",
    "                'age_days': age_days,\n",
    "                'created': created_time\n",
    "            })\n",
    "\n",
    "    return archivable\n",
    "\n",
    "# Check cleanup\n",
    "archivable_versions = check_cleanup_needed(MODEL_NAME, cleanup_policy)\n",
    "\n",
    "print(f\"\\n=== Cleanup Analysis ===\")\n",
    "print(f\"Total versions: {len(all_versions)}\")\n",
    "print(f\"Archivable versions: {len(archivable_versions)}\")\n",
    "\n",
    "if archivable_versions:\n",
    "    print(\"\\nVersions eligible for archiving:\")\n",
    "    for v in archivable_versions:\n",
    "        print(f\"  Version {v['version']}: {v['age_days']} days old (created {v['created']})\")\n",
    "else:\n",
    "    print(\"\\n✓ No versions need archiving at this time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2f2cec5-7fb8-4d7d-888d-7dd7e7655686",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 9: End-to-End Workflow Summary\n",
    "\n",
    "Let's create a comprehensive summary of everything we've accomplished in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5dbedcd-3709-4c64-a950-270fc47dd1e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\nMLflow & UNITY CATALOG LAB - COMPLETE WORKFLOW SUMMARY\n================================================================================\n\nLab Completion Date: 2025-10-06 00:08:55\n\n================================================================================\nSECTION 1: DATA PREPARATION\n================================================================================\n\n✓ Generated 10,000 customer records with realistic churn patterns\n✓ Created Unity Catalog structure:\n  - Catalog: financial_services\n  - Schema: churn_models\n  - Table: customer_churn_data\n✓ Saved data to Delta table with ACID guarantees\n✓ Performed data quality validation\n✓ Churn rate: 20.49%\n\n================================================================================\nSECTION 2: FEATURE ENGINEERING\n================================================================================\n\n✓ Prepared 14 features for modeling\n✓ Split data: 8,000 train / 2,000 test samples\n✓ Applied feature scaling for model optimization\n✓ Maintained stratified class distribution\n\n================================================================================\nSECTION 3: MODEL TRAINING & EXPERIMENT TRACKING\n================================================================================\n\n✓ Trained 3 different models:\n  1. Logistic Regression (Baseline)\n  2. Random Forest v1\n  3. Gradient Boosting v1\n\n✓ Logged to MLflow for each model:\n  - Hyperparameters\n  - Performance metrics (Accuracy, Precision, Recall, F1, AUC)\n  - Model artifacts\n  - Feature importance plots\n  - Training metadata and tags\n\n✓ Best Model: Gradient Boosting\n  - F1 Score: 0.3207\n  - AUC-ROC: 0.7703\n\n================================================================================\nSECTION 4: MODEL REGISTRATION\n================================================================================\n\n✓ Registered best model to Unity Catalog Model Registry\n✓ Model Name: financial_services.churn_models.customer_churn_model\n✓ Initial Version: 39\n✓ Added comprehensive documentation\n✓ Included performance metrics and limitations\n\n================================================================================\nSECTION 5: VERSION MANAGEMENT\n================================================================================\n\n✓ Trained improved model (Random Forest v2)\n✓ Registered as new version: 40\n✓ Set model aliases:\n  - Champion (Production): Version 39\n  - Challenger (A/B Test): Version 40\n✓ Demonstrated version comparison and selection\n\n================================================================================\nSECTION 6: GOVERNANCE & COMPLIANCE\n================================================================================\n\n✓ Unity Catalog RBAC:\n  - Fine-grained access control on data and models\n  - Role-based permissions for different teams\n\n✓ Audit Logging:\n  - All operations automatically logged\n  - Complete trail for regulatory compliance\n\n✓ Data Lineage:\n  - Full traceability from data to model to deployment\n  - Accessible through Unity Catalog UI\n\n================================================================================\nSECTION 7: REPRODUCIBILITY\n================================================================================\n\n✓ All experiments fully reproducible via MLflow\n✓ Complete parameter and metric logging\n✓ Model artifacts stored with signatures\n✓ Training data versioned in Unity Catalog\n✓ Generated comprehensive performance report\n\n================================================================================\nSECTION 8: ARCHIVING & CLEANUP\n================================================================================\n\n✓ Defined cleanup policies:\n  - Retain Champion and Challenger models\n  - Archive versions older than 90 days\n  - Maximum 10 versions per model\n\n✓ Implemented archiving workflow\n✓ Maintained audit trail for archived models\n\n================================================================================\nKEY ACHIEVEMENTS\n================================================================================\n\n1. ✓ Complete MLflow experiment tracking implementation\n2. ✓ Unity Catalog integration for enterprise governance\n3. ✓ Model versioning and lifecycle management\n4. ✓ RBAC and access control setup\n5. ✓ Audit logging and compliance readiness\n6. ✓ Data lineage tracking\n7. ✓ Reproducibility best practices\n8. ✓ Archiving and cleanup policies\n\n================================================================================\nPRODUCTION READINESS CHECKLIST\n================================================================================\n\n✓ Models trained and validated\n✓ Best model registered in Unity Catalog\n✓ Documentation complete\n✓ Governance controls in place\n✓ Audit trail established\n✓ Monitoring framework defined\n✓ Cleanup policies implemented\n✓ Team access controls configured\n\n================================================================================\nNEXT STEPS\n================================================================================\n\n1. Deploy Champion model to production endpoint\n2. Set up A/B testing infrastructure for Challenger\n3. Implement real-time monitoring dashboard\n4. Schedule quarterly model retraining\n5. Establish model performance review cadence\n6. Configure alerting for model drift\n7. Document deployment procedures\n8. Train team on model operations\n\n================================================================================\nCOMPLIANCE NOTES\n================================================================================\n\n✓ All data stored with access controls\n✓ Complete audit trail maintained\n✓ Model lineage fully documented\n✓ Reproducibility guaranteed\n✓ Regulatory requirements met\n✓ Ready for compliance review\n\n================================================================================\nLAB COMPLETE - ENTERPRISE ML GOVERNANCE ACHIEVED\n================================================================================\n\n\n✓ Lab summary saved to /tmp/lab_summary.txt\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive summary\n",
    "summary = f\"\"\"\n",
    "{'='*80}\n",
    "MLflow & UNITY CATALOG LAB - COMPLETE WORKFLOW SUMMARY\n",
    "{'='*80}\n",
    "\n",
    "Lab Completion Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "{'='*80}\n",
    "SECTION 1: DATA PREPARATION\n",
    "{'='*80}\n",
    "\n",
    "✓ Generated {n_customers:,} customer records with realistic churn patterns\n",
    "✓ Created Unity Catalog structure:\n",
    "  - Catalog: {CATALOG_NAME}\n",
    "  - Schema: {SCHEMA_NAME}\n",
    "  - Table: {TABLE_NAME}\n",
    "✓ Saved data to Delta table with ACID guarantees\n",
    "✓ Performed data quality validation\n",
    "✓ Churn rate: {df_pandas['churn'].mean():.2%}\n",
    "\n",
    "{'='*80}\n",
    "SECTION 2: FEATURE ENGINEERING\n",
    "{'='*80}\n",
    "\n",
    "✓ Prepared {X.shape[1]} features for modeling\n",
    "✓ Split data: {X_train.shape[0]:,} train / {X_test.shape[0]:,} test samples\n",
    "✓ Applied feature scaling for model optimization\n",
    "✓ Maintained stratified class distribution\n",
    "\n",
    "{'='*80}\n",
    "SECTION 3: MODEL TRAINING & EXPERIMENT TRACKING\n",
    "{'='*80}\n",
    "\n",
    "✓ Trained 3 different models:\n",
    "  1. Logistic Regression (Baseline)\n",
    "  2. Random Forest v1\n",
    "  3. Gradient Boosting v1\n",
    "\n",
    "✓ Logged to MLflow for each model:\n",
    "  - Hyperparameters\n",
    "  - Performance metrics (Accuracy, Precision, Recall, F1, AUC)\n",
    "  - Model artifacts\n",
    "  - Feature importance plots\n",
    "  - Training metadata and tags\n",
    "\n",
    "✓ Best Model: {best_model_name}\n",
    "  - F1 Score: {comparison_df.loc[best_model_idx, 'F1_Score']:.4f}\n",
    "  - AUC-ROC: {comparison_df.loc[best_model_idx, 'AUC']:.4f}\n",
    "\n",
    "{'='*80}\n",
    "SECTION 4: MODEL REGISTRATION\n",
    "{'='*80}\n",
    "\n",
    "✓ Registered best model to Unity Catalog Model Registry\n",
    "✓ Model Name: {MODEL_NAME}\n",
    "✓ Initial Version: {model_version.version}\n",
    "✓ Added comprehensive documentation\n",
    "✓ Included performance metrics and limitations\n",
    "\n",
    "{'='*80}\n",
    "SECTION 5: VERSION MANAGEMENT\n",
    "{'='*80}\n",
    "\n",
    "✓ Trained improved model (Random Forest v2)\n",
    "✓ Registered as new version: {model_version_v2.version}\n",
    "✓ Set model aliases:\n",
    "  - Champion (Production): Version {model_version.version}\n",
    "  - Challenger (A/B Test): Version {model_version_v2.version}\n",
    "✓ Demonstrated version comparison and selection\n",
    "\n",
    "{'='*80}\n",
    "SECTION 6: GOVERNANCE & COMPLIANCE\n",
    "{'='*80}\n",
    "\n",
    "✓ Unity Catalog RBAC:\n",
    "  - Fine-grained access control on data and models\n",
    "  - Role-based permissions for different teams\n",
    "\n",
    "✓ Audit Logging:\n",
    "  - All operations automatically logged\n",
    "  - Complete trail for regulatory compliance\n",
    "\n",
    "✓ Data Lineage:\n",
    "  - Full traceability from data to model to deployment\n",
    "  - Accessible through Unity Catalog UI\n",
    "\n",
    "{'='*80}\n",
    "SECTION 7: REPRODUCIBILITY\n",
    "{'='*80}\n",
    "\n",
    "✓ All experiments fully reproducible via MLflow\n",
    "✓ Complete parameter and metric logging\n",
    "✓ Model artifacts stored with signatures\n",
    "✓ Training data versioned in Unity Catalog\n",
    "✓ Generated comprehensive performance report\n",
    "\n",
    "{'='*80}\n",
    "SECTION 8: ARCHIVING & CLEANUP\n",
    "{'='*80}\n",
    "\n",
    "✓ Defined cleanup policies:\n",
    "  - Retain Champion and Challenger models\n",
    "  - Archive versions older than 90 days\n",
    "  - Maximum 10 versions per model\n",
    "\n",
    "✓ Implemented archiving workflow\n",
    "✓ Maintained audit trail for archived models\n",
    "\n",
    "{'='*80}\n",
    "KEY ACHIEVEMENTS\n",
    "{'='*80}\n",
    "\n",
    "1. ✓ Complete MLflow experiment tracking implementation\n",
    "2. ✓ Unity Catalog integration for enterprise governance\n",
    "3. ✓ Model versioning and lifecycle management\n",
    "4. ✓ RBAC and access control setup\n",
    "5. ✓ Audit logging and compliance readiness\n",
    "6. ✓ Data lineage tracking\n",
    "7. ✓ Reproducibility best practices\n",
    "8. ✓ Archiving and cleanup policies\n",
    "\n",
    "{'='*80}\n",
    "PRODUCTION READINESS CHECKLIST\n",
    "{'='*80}\n",
    "\n",
    "✓ Models trained and validated\n",
    "✓ Best model registered in Unity Catalog\n",
    "✓ Documentation complete\n",
    "✓ Governance controls in place\n",
    "✓ Audit trail established\n",
    "✓ Monitoring framework defined\n",
    "✓ Cleanup policies implemented\n",
    "✓ Team access controls configured\n",
    "\n",
    "{'='*80}\n",
    "NEXT STEPS\n",
    "{'='*80}\n",
    "\n",
    "1. Deploy Champion model to production endpoint\n",
    "2. Set up A/B testing infrastructure for Challenger\n",
    "3. Implement real-time monitoring dashboard\n",
    "4. Schedule quarterly model retraining\n",
    "5. Establish model performance review cadence\n",
    "6. Configure alerting for model drift\n",
    "7. Document deployment procedures\n",
    "8. Train team on model operations\n",
    "\n",
    "{'='*80}\n",
    "COMPLIANCE NOTES\n",
    "{'='*80}\n",
    "\n",
    "✓ All data stored with access controls\n",
    "✓ Complete audit trail maintained\n",
    "✓ Model lineage fully documented\n",
    "✓ Reproducibility guaranteed\n",
    "✓ Regulatory requirements met\n",
    "✓ Ready for compliance review\n",
    "\n",
    "{'='*80}\n",
    "LAB COMPLETE - ENTERPRISE ML GOVERNANCE ACHIEVED\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save summary\n",
    "with open('/tmp/lab_summary.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"\\n✓ Lab summary saved to /tmp/lab_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21ae9f6e-0cc3-4dbd-95f2-80a66b306ae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 10: Hands-On Exercises\n",
    "\n",
    "Now that you've completed the guided lab, try these exercises to reinforce your learning:\n",
    "\n",
    "### Exercise 1: Train a New Model\n",
    "- Train a new model with different hyperparameters\n",
    "- Log it to MLflow with appropriate tags\n",
    "- Compare its performance to existing models\n",
    "\n",
    "### Exercise 2: Promote a Model\n",
    "- Choose the best performing model\n",
    "- Promote it to Champion\n",
    "- Document the promotion decision\n",
    "\n",
    "### Exercise 3: Query Audit Logs\n",
    "- Query Unity Catalog audit logs\n",
    "- Find all operations on your model\n",
    "- Create a compliance report\n",
    "\n",
    "### Exercise 4: Implement Monitoring\n",
    "- Create a monitoring dashboard\n",
    "- Track model performance over time\n",
    "- Set up alerts for performance degradation\n",
    "\n",
    "### Exercise 5: Archive Old Versions\n",
    "- Identify versions that should be archived\n",
    "- Apply archiving tags\n",
    "- Document archiving decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67750962-2af5-4135-aac8-643822541318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've completed a comprehensive lab on MLflow and Unity Catalog for enterprise ML governance.\n",
    "\n",
    "### What You've Learned:\n",
    "\n",
    "1. **MLflow Experiment Tracking**\n",
    "   - Logging parameters, metrics, and artifacts\n",
    "   - Organizing experiments for team collaboration\n",
    "   - Comparing model performance\n",
    "\n",
    "2. **Model Registry with Unity Catalog**\n",
    "   - Registering models with versioning\n",
    "   - Managing model lifecycle with aliases\n",
    "   - Loading models for inference\n",
    "\n",
    "3. **Enterprise Governance**\n",
    "   - RBAC for access control\n",
    "   - Audit logging for compliance\n",
    "   - Data lineage tracking\n",
    "\n",
    "4. **Best Practices**\n",
    "   - Reproducibility through comprehensive logging\n",
    "   - Documentation for stakeholders\n",
    "   - Archiving and cleanup policies\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "This workflow is used in production environments for:\n",
    "- Financial services (fraud detection, credit scoring)\n",
    "- Healthcare (patient risk prediction, diagnosis support)\n",
    "- Retail (customer churn, demand forecasting)\n",
    "- Manufacturing (predictive maintenance, quality control)\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)\n",
    "- [Unity Catalog Documentation](https://docs.databricks.com/data-governance/unity-catalog/index.html)\n",
    "- [Databricks ML Best Practices](https://docs.databricks.com/machine-learning/index.html)\n",
    "\n",
    "### Thank You!\n",
    "\n",
    "You're now equipped to implement enterprise-grade ML governance in your organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eef8e380-6b98-48c0-b114-4ea267b91f89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\nLAB RESOURCES - QUICK REFERENCE\n================================================================================\n\n\uD83D\uDCCA Data Table: financial_services.churn_models.customer_churn_data\n\uD83E\uDD16 Model Registry: financial_services.churn_models.customer_churn_model\n\uD83D\uDD2C Experiment: /Users/rajaniesh@rajanieshkaushikk.com/churn_prediction_experiments\n\n\uD83D\uDCC8 Model Versions:\n   - Champion: Version 39\n   - Challenger: Version 40\n\n\uD83D\uDCC1 Generated Reports:\n   - Performance Report: /tmp/model_performance_report.txt\n   - Lab Summary: /tmp/lab_summary.txt\n\n✅ Lab Status: COMPLETE\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final verification - Display key resources\n",
    "print(\"=\"*80)\n",
    "print(\"LAB RESOURCES - QUICK REFERENCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n\uD83D\uDCCA Data Table: {table_path}\")\n",
    "print(f\"\uD83E\uDD16 Model Registry: {MODEL_NAME}\")\n",
    "print(f\"\uD83D\uDD2C Experiment: {experiment_name}\")\n",
    "print(f\"\\n\uD83D\uDCC8 Model Versions:\")\n",
    "print(f\"   - Champion: Version {model_version.version}\")\n",
    "print(f\"   - Challenger: Version {model_version_v2.version}\")\n",
    "print(f\"\\n\uD83D\uDCC1 Generated Reports:\")\n",
    "print(f\"   - Performance Report: /tmp/model_performance_report.txt\")\n",
    "print(f\"   - Lab Summary: /tmp/lab_summary.txt\")\n",
    "print(f\"\\n✅ Lab Status: COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Orielly Chapter 6",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
